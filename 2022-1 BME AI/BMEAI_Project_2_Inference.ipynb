{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "936b7086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "standard = StandardScaler()\n",
    "minmax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c25fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7a6fcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807f3f74",
   "metadata": {},
   "source": [
    "# Train Set / Validation Set 나누기\n",
    "- 앞서 train 단계에서 진행한 것과 같이 데이터를 나눠줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b233a61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x170</th>\n",
       "      <th>x171</th>\n",
       "      <th>x172</th>\n",
       "      <th>x173</th>\n",
       "      <th>x174</th>\n",
       "      <th>x175</th>\n",
       "      <th>x176</th>\n",
       "      <th>x177</th>\n",
       "      <th>x178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>-38</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>-94</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>-79</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-59</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11495</th>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-23</td>\n",
       "      <td>-26</td>\n",
       "      <td>-36</td>\n",
       "      <td>-42</td>\n",
       "      <td>-45</td>\n",
       "      <td>-42</td>\n",
       "      <td>-45</td>\n",
       "      <td>-49</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-18</td>\n",
       "      <td>-37</td>\n",
       "      <td>-47</td>\n",
       "      <td>-48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11496</th>\n",
       "      <td>-47</td>\n",
       "      <td>-11</td>\n",
       "      <td>28</td>\n",
       "      <td>77</td>\n",
       "      <td>141</td>\n",
       "      <td>211</td>\n",
       "      <td>246</td>\n",
       "      <td>240</td>\n",
       "      <td>193</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>-65</td>\n",
       "      <td>-33</td>\n",
       "      <td>-7</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>77</td>\n",
       "      <td>117</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11497</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>-13</td>\n",
       "      <td>-16</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>-9</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-65</td>\n",
       "      <td>-48</td>\n",
       "      <td>-61</td>\n",
       "      <td>-62</td>\n",
       "      <td>-67</td>\n",
       "      <td>-30</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11498</th>\n",
       "      <td>-40</td>\n",
       "      <td>-25</td>\n",
       "      <td>-9</td>\n",
       "      <td>-12</td>\n",
       "      <td>-2</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>135</td>\n",
       "      <td>148</td>\n",
       "      <td>143</td>\n",
       "      <td>116</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>29</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>-59</td>\n",
       "      <td>-25</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11500 rows × 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x1   x2   x3   x4   x5   x6   x7   x8   x9  x10  ...  x170  x171  \\\n",
       "0      135  190  229  223  192  125   55   -9  -33  -38  ...   -17   -15   \n",
       "1      386  382  356  331  320  315  307  272  244  232  ...   164   150   \n",
       "2      -32  -39  -47  -37  -32  -36  -57  -73  -85  -94  ...    57    64   \n",
       "3     -105 -101  -96  -92  -89  -95 -102 -100  -87  -79  ...   -82   -81   \n",
       "4       -9  -65  -98 -102  -78  -48  -16    0  -21  -59  ...     4     2   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "11495  -22  -22  -23  -26  -36  -42  -45  -42  -45  -49  ...    15    16   \n",
       "11496  -47  -11   28   77  141  211  246  240  193  136  ...   -65   -33   \n",
       "11497   14    6  -13  -16   10   26   27   -9    4   14  ...   -65   -48   \n",
       "11498  -40  -25   -9  -12   -2   12    7   19   22   29  ...   121   135   \n",
       "11499   29   41   57   72   74   62   54   43   31   23  ...   -59   -25   \n",
       "\n",
       "       x172  x173  x174  x175  x176  x177  x178  y  \n",
       "0       -31   -77  -103  -127  -116   -83   -51  2  \n",
       "1       146   152   157   156   154   143   129  0  \n",
       "2        48    19   -12   -30   -35   -35   -36  2  \n",
       "3       -80   -77   -85   -77   -72   -69   -65  2  \n",
       "4       -12   -32   -41   -65   -83   -89   -73  2  \n",
       "...     ...   ...   ...   ...   ...   ...   ... ..  \n",
       "11495    12     5    -1   -18   -37   -47   -48  1  \n",
       "11496    -7    14    27    48    77   117   170  0  \n",
       "11497   -61   -62   -67   -30    -2    -1    -8  2  \n",
       "11498   148   143   116    86    68    59    55  2  \n",
       "11499    -4     2     5     4    -2     2    20  2  \n",
       "\n",
       "[11500 rows x 179 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv('C:\\\\Users\\\\mingu\\\\Desktop\\\\data.csv')\n",
    "d = d.drop('column_a',axis = 1)\n",
    "d['y'] = d['y']-1\n",
    "d.loc[(d['y'] != 0) & (d['y'] != 1) , 'y'] = 2\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a7f15a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label의 비율을 고려하여 train set / validation set 생성\n",
    "d_0 = d[d['y']==0].copy()\n",
    "d_0_train = d_0[:1800].copy()\n",
    "d_0_test = d_0[1800:].copy()\n",
    "\n",
    "d_1 = d[d['y']==1].copy()\n",
    "d_1_train = d_1[:1800].copy()\n",
    "d_1_test = d_1[1800:].copy()\n",
    "\n",
    "d_2 = d[d['y']==2].copy()\n",
    "d_2_train = d_2[:5400].copy()\n",
    "d_2_test = d_2[5400:].copy()\n",
    "\n",
    "train = pd.concat([d_0_train, d_1_train, d_2_train])\n",
    "test = pd.concat([d_0_test, d_1_test, d_2_test])\n",
    "\n",
    "train_x = train.drop(['y'], axis = 1).copy()\n",
    "train_y = train['y'].copy()\n",
    "\n",
    "test_x = test.drop(['y'], axis = 1).copy()\n",
    "test_y = test['y'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a61cf2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG 신호의 noise를 고려해주기 위해 정규화 진행\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standard = StandardScaler()\n",
    "\n",
    "train_x_st = standard.fit_transform(train_x)\n",
    "test_x_st = standard.fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc2891d",
   "metadata": {},
   "source": [
    "# 모델 가져오기\n",
    "- 앞서 train 단계에서 만든 모델을 그대로 가져와서 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dcc4563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myRNN(\n",
       "  (features): Sequential(\n",
       "    (0): LSTM(15, 40, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=40, out_features=20, bias=True)\n",
       "    (1): Linear(in_features=20, out_features=40, bias=True)\n",
       "    (2): Linear(in_features=40, out_features=20, bias=True)\n",
       "    (3): Linear(in_features=20, out_features=40, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Linear(in_features=40, out_features=40, bias=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (output): Linear(in_features=40, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myRNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.features = torch.nn.Sequential(    \n",
    "            \n",
    "            #torch.nn.Linear(input_size, hidden_size),\n",
    "            #torch.nn.ReLU(inplace=True),\n",
    "            #torch.nn.Dropout(0.2), \n",
    "            \n",
    "            #torch.nn.Linear(hidden_size, 256),\n",
    "            #torch.nn.Linear(256,256),\n",
    "            #torch.nn.Linear(256,128),\n",
    "            #torch.nn.Linear(128, hidden_size),\n",
    "            #torch.nn.ReLU(),    \n",
    "\n",
    "            #torch.nn.RNN(input_size=input_size,\n",
    "            #torch.nn.LSTM(input_size=input_size,\n",
    "            #torch.nn.GRU(input_size=input_size,\n",
    "            torch.nn.LSTM(input_size=input_size,\n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=num_layers,\n",
    "                          batch_first=True,\n",
    "                          bidirectional=False,\n",
    "                          dropout=0.3)\n",
    "    )\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size, 20),\n",
    "            torch.nn.Linear(20,40),\n",
    "            torch.nn.Linear(40,20),\n",
    "            torch.nn.Linear(20, hidden_size),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(hidden_size, hidden_size),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(0.3),\n",
    "        )\n",
    "        \n",
    "        self.output = torch.nn.Linear(hidden_size, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features, _ = self.features(x)\n",
    "        output = self.classifier(features)\n",
    "        output = self.output(output)\n",
    "        return output\n",
    "    \n",
    "net = myRNN(15,40,2,3)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183dc1d",
   "metadata": {},
   "source": [
    "# 파라미터 업로드\n",
    "- 앞서 train 단계에서 만들어둔 파라미터 파일의 경로로부터 파라미터를 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dacaa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myRNN(\n",
       "  (features): Sequential(\n",
       "    (0): LSTM(15, 40, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=40, out_features=20, bias=True)\n",
       "    (1): Linear(in_features=20, out_features=40, bias=True)\n",
       "    (2): Linear(in_features=40, out_features=20, bias=True)\n",
       "    (3): Linear(in_features=20, out_features=40, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Linear(in_features=40, out_features=40, bias=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (output): Linear(in_features=40, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가져올 경로 설정\n",
    "PATH_param = \"C:\\\\Users\\\\mingu\\\\Desktop\\\\state_dict_model.pt\"\n",
    "\n",
    "# 로드\n",
    "net.load_state_dict(torch.load(PATH_param))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba161d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('features.0.weight_ih_l0',\n",
       "              tensor([[ 0.3825,  0.1696,  0.3888,  ..., -0.0149, -0.2796, -1.0081],\n",
       "                      [ 1.0355,  0.5075,  0.2560,  ...,  0.2613,  0.3488, -0.2009],\n",
       "                      [-0.4147, -0.5194, -0.4410,  ..., -0.0834,  0.1688,  0.4171],\n",
       "                      ...,\n",
       "                      [-0.6725, -0.4227, -0.0128,  ..., -0.2711, -0.3587, -0.4195],\n",
       "                      [-0.1928, -0.1214,  0.5168,  ...,  0.1447, -0.2058, -0.0991],\n",
       "                      [ 0.2795,  0.3319,  0.5523,  ...,  0.0381,  0.1327,  0.0728]])),\n",
       "             ('features.0.weight_hh_l0',\n",
       "              tensor([[ 0.5270, -0.2079, -0.4816,  ..., -0.3560,  0.3740,  0.4470],\n",
       "                      [-0.0881, -0.4017,  0.0637,  ..., -1.4737, -1.3834,  1.5079],\n",
       "                      [-0.3759, -0.4179, -0.2526,  ..., -0.3713,  0.2377, -1.0464],\n",
       "                      ...,\n",
       "                      [-0.5668, -0.5449, -0.3781,  ..., -0.5061,  0.1073, -0.1213],\n",
       "                      [-0.3803, -0.8716, -0.6513,  ...,  0.5136,  0.0681, -0.7724],\n",
       "                      [ 0.4183,  0.3132, -0.1342,  ..., -0.4445,  0.0959, -1.0603]])),\n",
       "             ('features.0.bias_ih_l0',\n",
       "              tensor([-0.3037, -0.2606, -0.3316,  0.0233, -0.4439, -0.1046,  0.1608, -0.2834,\n",
       "                      -0.0142, -0.0784, -0.1524, -0.1322, -0.0540, -0.2617, -0.1949,  0.0443,\n",
       "                      -0.1807, -0.1938,  0.3962,  0.0163, -0.1656, -0.2311, -0.0780,  0.0687,\n",
       "                      -0.2029, -0.1608,  0.1490,  0.2850, -0.1172, -0.2283, -0.2111, -0.0626,\n",
       "                      -0.0365,  0.1080,  0.1199, -0.0912, -0.1342, -0.3252,  0.2411, -0.1226,\n",
       "                      -0.4843, -0.0397,  0.0275,  0.0683, -0.0301,  0.0058, -0.1072, -0.2235,\n",
       "                      -0.1540,  0.0142, -0.1486, -0.2154, -0.1161, -0.2184, -0.3175,  0.2835,\n",
       "                       0.1052,  0.1777, -0.5243, -0.1001, -0.2081, -0.3603, -0.2685,  0.1517,\n",
       "                      -0.3221,  0.0579, -0.5158,  0.1802, -0.3705, -0.2376, -0.1590, -0.4760,\n",
       "                      -0.0525, -0.8376, -0.0562, -0.2380, -0.1882,  0.0248,  0.1251, -0.1387,\n",
       "                       0.0694,  0.0293,  0.2192, -0.0732, -0.0145,  0.1597, -0.2210, -0.0895,\n",
       "                       0.1128,  0.2539, -0.1450,  0.2442,  0.0405,  0.0396, -0.0591,  0.1917,\n",
       "                      -0.1240,  0.1172,  0.0399, -0.1996, -0.1907,  0.0632, -0.0013,  0.0859,\n",
       "                       0.1706, -0.1112, -0.1126, -0.0915,  0.0491, -0.0887, -0.0744, -0.1686,\n",
       "                      -0.0208, -0.1932,  0.0497,  0.2502, -0.3020,  0.0371,  0.0942,  0.2541,\n",
       "                       0.6838,  0.2764,  0.5228,  0.0855,  0.2911,  0.4065,  0.6679,  0.3688,\n",
       "                       1.1023,  0.3135,  0.0623,  0.2973,  0.1417,  0.1821,  0.4667,  0.5933,\n",
       "                       0.6023,  0.1938,  0.3962,  1.0153,  0.2536,  0.1759,  0.2194, -0.1925,\n",
       "                       0.2180,  0.6017,  0.3551,  0.0334,  0.3594,  0.5033,  0.0987,  0.1145,\n",
       "                       0.6504,  0.3280,  0.5699,  0.4332,  0.2133,  0.3643,  0.5167,  0.2896])),\n",
       "             ('features.0.bias_hh_l0',\n",
       "              tensor([-0.2139, -0.0738, -0.3700,  0.1758, -0.4371, -0.1258,  0.2223, -0.3177,\n",
       "                       0.0119, -0.1689, -0.0552, -0.2166,  0.1699, -0.2828, -0.2188,  0.1748,\n",
       "                      -0.1608,  0.0089,  0.3953, -0.0758, -0.1291, -0.1447, -0.0018,  0.0853,\n",
       "                      -0.2613, -0.3904,  0.0234,  0.3703, -0.0307, -0.0478, -0.0981, -0.2325,\n",
       "                      -0.0397,  0.0625, -0.0210,  0.0654,  0.0625, -0.3066,  0.1359,  0.0665,\n",
       "                      -0.4201, -0.0375, -0.1236, -0.0051, -0.2269,  0.0487, -0.0213, -0.1550,\n",
       "                       0.0434, -0.1281, -0.1676, -0.2508, -0.1925, -0.3572, -0.2964,  0.1870,\n",
       "                       0.1596,  0.0329, -0.3407,  0.0461, -0.3985, -0.2723, -0.1609,  0.1203,\n",
       "                      -0.2912, -0.0667, -0.5980, -0.1081, -0.5951, -0.1030, -0.0633, -0.2784,\n",
       "                      -0.0873, -0.6206, -0.1953, -0.2090, -0.2549,  0.0547,  0.1548, -0.1914,\n",
       "                       0.0169, -0.1081,  0.0444, -0.0297,  0.0421,  0.2813, -0.2221,  0.1267,\n",
       "                       0.0189,  0.0592,  0.0349,  0.2417,  0.1105, -0.0716,  0.1529,  0.1123,\n",
       "                      -0.1125,  0.0592, -0.0809,  0.0066, -0.1595,  0.1966,  0.2495,  0.0587,\n",
       "                       0.2820, -0.1332,  0.0560, -0.0404,  0.0664,  0.0157, -0.1441,  0.0461,\n",
       "                      -0.0741,  0.0173,  0.2105,  0.1687, -0.2714,  0.1069, -0.0074,  0.0112,\n",
       "                       0.6568,  0.2804,  0.5723,  0.0950,  0.3021,  0.4355,  0.4688,  0.4519,\n",
       "                       0.9330,  0.5587, -0.1610,  0.1055, -0.0783,  0.3690,  0.2710,  0.5628,\n",
       "                       0.5287,  0.3329,  0.3202,  0.7999,  0.4281,  0.1735,  0.3032, -0.0093,\n",
       "                       0.2106,  0.8953,  0.4841, -0.0569,  0.5789,  0.6885,  0.0177, -0.1510,\n",
       "                       0.4773,  0.0912,  0.3529,  0.2530,  0.3311,  0.3573,  0.5371,  0.3572])),\n",
       "             ('features.0.weight_ih_l1',\n",
       "              tensor([[ 0.3335, -0.4483, -0.1688,  ..., -0.2083, -0.0090, -0.2028],\n",
       "                      [-0.3441,  0.3875, -1.4923,  ..., -1.3286,  0.2710, -0.1128],\n",
       "                      [-0.2207, -0.1087,  0.2885,  ...,  0.6592, -0.7770,  0.4367],\n",
       "                      ...,\n",
       "                      [ 0.3468, -0.2677,  0.1823,  ..., -0.1313, -0.4181,  0.1614],\n",
       "                      [-0.1338,  0.0341, -1.0903,  ..., -0.7132, -0.1374,  0.4428],\n",
       "                      [-0.7667,  0.5466,  0.3552,  ..., -0.2494, -0.1371, -0.3281]])),\n",
       "             ('features.0.weight_hh_l1',\n",
       "              tensor([[-0.9653,  0.6542,  0.6799,  ..., -0.2262, -0.3813,  0.3174],\n",
       "                      [ 0.0578, -0.1004,  0.6740,  ..., -1.1156,  1.3155,  0.1746],\n",
       "                      [ 0.3841, -0.8703,  0.1018,  ...,  0.6680,  0.1338, -0.7458],\n",
       "                      ...,\n",
       "                      [-1.0017, -0.5094, -0.1728,  ...,  0.5427, -0.2250, -0.9911],\n",
       "                      [-0.5875,  0.5265,  0.5961,  ..., -0.8839,  0.0569, -0.0899],\n",
       "                      [ 0.6559,  0.5470,  0.5160,  ...,  0.2252, -0.2403, -0.1488]])),\n",
       "             ('features.0.bias_ih_l1',\n",
       "              tensor([-0.0588,  0.1113,  0.1187, -0.1017,  0.0154,  0.2418,  0.3456,  0.0528,\n",
       "                      -0.2468, -0.2235, -0.0237, -0.2472,  0.1670, -0.1182, -0.1132,  0.0433,\n",
       "                       0.1650,  0.1419, -0.3196, -0.3730, -0.3611, -0.0854,  0.3168, -0.6089,\n",
       "                      -0.0847,  0.4175,  0.0588, -0.1276, -0.2978,  0.1346,  0.2438, -0.1324,\n",
       "                      -0.1332,  0.1514,  0.4739,  0.3322,  0.1240,  0.3284, -0.0150,  0.1859,\n",
       "                      -0.4074, -0.1952,  0.3803,  0.0750,  0.2835,  0.1168,  0.2618,  0.3544,\n",
       "                       0.0319, -0.0864,  0.1182,  0.1960, -0.0202, -0.1466,  0.5726,  0.3094,\n",
       "                       0.0511,  0.1821, -0.0695,  0.2598, -0.3445, -0.0266, -0.0813,  0.2142,\n",
       "                      -0.2754,  0.3733,  0.0303, -0.1556, -0.2888, -0.2173, -0.6232,  0.1710,\n",
       "                       0.1223,  0.2358, -0.1485,  0.0613,  0.0469,  0.1305,  0.2232,  0.1262,\n",
       "                       0.0490, -0.0903,  0.2218, -0.1933,  0.1082,  0.1652,  0.1537,  0.0259,\n",
       "                      -0.0420,  0.1594, -0.0511, -0.2872, -0.0176,  0.1541,  0.0063, -0.0721,\n",
       "                       0.0401,  0.1812,  0.1989, -0.1311,  0.0192, -0.0011, -0.0661,  0.0374,\n",
       "                       0.0054, -0.0879, -0.3276,  0.1148,  0.0118,  0.0810, -0.0761, -0.2014,\n",
       "                       0.0871, -0.0151,  0.1757,  0.0735,  0.1141,  0.2029,  0.1374, -0.0184,\n",
       "                      -0.1278,  0.3719,  0.3641,  0.3389,  0.1563,  0.1862,  0.1209,  0.4227,\n",
       "                       0.3833,  0.2431,  0.3145,  0.1638,  0.1004,  0.1538,  0.2639,  0.3445,\n",
       "                       0.3120,  0.2166, -0.0637,  0.4504,  0.0529,  0.1698,  0.2977, -0.1613,\n",
       "                       0.0846,  0.4404,  0.3231, -0.0219, -0.0366,  0.2146,  0.3808,  0.5431,\n",
       "                       0.0632,  0.5397,  0.6913,  0.4871,  0.3403,  0.3683,  0.0867,  0.5521])),\n",
       "             ('features.0.bias_hh_l1',\n",
       "              tensor([-0.0761,  0.2450,  0.0716,  0.0589, -0.0440,  0.1589,  0.2785, -0.0355,\n",
       "                      -0.1311, -0.1402, -0.0430, -0.3024,  0.1917, -0.0941, -0.2272,  0.2448,\n",
       "                       0.2867,  0.2675, -0.2733, -0.4003, -0.2368, -0.0824,  0.2974, -0.6605,\n",
       "                      -0.2188,  0.1521, -0.1301,  0.1516, -0.0824,  0.1067,  0.1795, -0.0170,\n",
       "                      -0.1327,  0.2891,  0.3249,  0.1693,  0.0237,  0.0887, -0.1200, -0.0481,\n",
       "                      -0.3236, -0.1258,  0.3262,  0.1982,  0.5607, -0.0547,  0.2857,  0.2654,\n",
       "                      -0.0490, -0.1341,  0.0975,  0.0423, -0.1506,  0.0297,  0.3044,  0.3172,\n",
       "                       0.0513,  0.0547,  0.0148, -0.0029, -0.1469, -0.0860, -0.1415,  0.2996,\n",
       "                      -0.0611,  0.2606,  0.0959, -0.0089, -0.1873, -0.1658, -0.5577,  0.4326,\n",
       "                       0.1678,  0.0191, -0.0916,  0.1704, -0.0859, -0.0506,  0.1269,  0.1370,\n",
       "                       0.1446, -0.0593,  0.2550, -0.1337, -0.0245,  0.1002,  0.0587,  0.0059,\n",
       "                       0.0262, -0.0211, -0.3161, -0.2244,  0.1964, -0.0284, -0.2124, -0.2389,\n",
       "                       0.0575,  0.1241,  0.0567,  0.1250,  0.0027, -0.1251,  0.1125, -0.1823,\n",
       "                      -0.0124,  0.0017, -0.2068, -0.0113, -0.0750,  0.2976, -0.1520, -0.2120,\n",
       "                      -0.1386,  0.0693,  0.1609,  0.1839, -0.0339, -0.0440,  0.0339, -0.2836,\n",
       "                      -0.0319,  0.5653,  0.2212,  0.2058,  0.2293,  0.1394,  0.1546,  0.3029,\n",
       "                       0.4175,  0.3283,  0.2857, -0.0391,  0.2674, -0.1222,  0.1467,  0.3729,\n",
       "                       0.3900,  0.1067,  0.1593,  0.4939,  0.1071,  0.2520,  0.1588, -0.0815,\n",
       "                       0.1813,  0.4028,  0.2573,  0.2345,  0.0326,  0.1089,  0.3066,  0.3974,\n",
       "                      -0.0866,  0.4584,  0.6936,  0.3064,  0.3777,  0.3121,  0.0122,  0.4306])),\n",
       "             ('classifier.0.weight',\n",
       "              tensor([[-1.7743e-01, -2.8686e-02,  2.9960e-01, -2.5693e-01,  2.9150e-01,\n",
       "                       -5.4506e-02, -9.3650e-02,  8.0844e-02,  2.5800e-01,  2.3492e-02,\n",
       "                       -3.4976e-02,  3.9070e-01,  1.7480e-01, -1.3892e-01, -1.6195e-01,\n",
       "                        7.0228e-02, -5.7673e-02, -2.3707e-01,  2.3890e-01,  3.7613e-01,\n",
       "                        1.5575e-01, -4.2272e-01, -1.5564e-01, -4.8403e-01,  7.9158e-02,\n",
       "                       -1.5318e-01,  5.6903e-01, -1.9355e-01,  4.4233e-01,  3.9581e-01,\n",
       "                        5.3988e-02,  2.1971e-01,  1.3954e-01,  6.4796e-02, -7.6386e-02,\n",
       "                        9.2050e-02, -2.8680e-02,  1.6521e-01,  1.1655e-01, -5.4388e-02],\n",
       "                      [ 2.9757e-01,  2.2697e-01, -5.8380e-02,  1.3272e-01, -1.4607e-01,\n",
       "                        1.9108e-01, -4.3597e-01,  6.7240e-02, -1.2982e-01, -4.2765e-01,\n",
       "                        4.3658e-01, -4.6344e-01, -1.8534e-01,  3.4715e-01,  9.6234e-02,\n",
       "                       -2.5426e-01, -1.7055e-01,  3.9243e-01, -2.2503e-01, -2.9722e-01,\n",
       "                       -1.8159e-01,  2.9914e-01,  3.2707e-02,  3.6413e-01, -3.4221e-01,\n",
       "                        1.3719e-01, -3.1425e-01,  2.7643e-01, -3.8598e-01,  3.4181e-01,\n",
       "                       -2.2158e-01, -1.7851e-01, -3.9267e-01, -2.5139e-01,  2.3428e-01,\n",
       "                       -1.9550e-01,  2.8261e-02,  1.0988e-01, -4.9014e-02,  4.1781e-02],\n",
       "                      [ 4.1362e-01,  1.3687e-01,  2.9256e-01, -2.7645e-01,  4.7098e-02,\n",
       "                        2.2514e-01, -3.0480e-01,  8.5813e-02,  3.7506e-01, -4.7312e-02,\n",
       "                       -1.6467e-01, -3.3722e-01,  4.7079e-01,  1.2768e-01, -1.1809e-01,\n",
       "                        2.8208e-01, -5.1553e-02, -4.4613e-02, -1.6655e-01, -1.5183e-01,\n",
       "                        1.5698e-01,  1.6414e-01, -8.6060e-02,  2.0845e-01,  3.3031e-02,\n",
       "                       -1.4589e-02,  2.8512e-01,  2.6156e-01, -3.6079e-01,  8.7779e-02,\n",
       "                       -5.1458e-01,  4.3539e-02, -1.4919e-01, -1.9446e-01,  2.5764e-01,\n",
       "                       -1.3415e-01, -2.5733e-01,  7.2215e-02, -4.0542e-01, -2.2587e-02],\n",
       "                      [-1.8404e-01, -4.9590e-01,  3.7358e-01, -1.3516e-01,  1.4582e-01,\n",
       "                       -3.9504e-01,  4.1614e-01,  2.2091e-01, -2.0567e-02,  3.7656e-01,\n",
       "                       -3.0923e-01,  3.8058e-01,  1.9599e-01, -4.9684e-01, -1.1688e-01,\n",
       "                        2.4244e-01,  3.2739e-01, -4.0058e-01, -8.7107e-02,  3.5700e-01,\n",
       "                        5.9581e-01,  4.1450e-01,  7.1498e-01, -4.8673e-01,  1.6408e-01,\n",
       "                        3.7473e-02,  1.2969e-01, -3.0175e-01,  4.2440e-01, -4.4608e-01,\n",
       "                        5.1542e-02,  1.8555e-01,  7.0566e-01,  4.2415e-01, -1.6950e-01,\n",
       "                        4.8067e-01,  3.0447e-01,  3.2608e-02, -3.1213e-01, -1.7811e-01],\n",
       "                      [-1.4609e-01, -1.3985e-01, -1.4440e-02, -2.1930e-03,  4.8421e-02,\n",
       "                       -1.1526e-02,  3.9676e-01, -1.3278e-01,  6.5089e-03,  4.5793e-01,\n",
       "                        1.1329e-01,  2.1395e-01, -2.5350e-01, -1.6931e-01,  1.0991e-01,\n",
       "                       -1.9996e-01,  9.9763e-03, -6.6593e-02,  3.3496e-01,  1.1858e-02,\n",
       "                       -3.2118e-01, -2.2131e-01, -6.4997e-03, -1.5339e-01,  2.2271e-01,\n",
       "                       -2.9061e-01, -2.5894e-01, -1.7017e-01,  1.5301e-01, -2.6742e-01,\n",
       "                        2.1030e-01, -2.5572e-02,  1.0956e-01,  5.5525e-02, -2.1550e-01,\n",
       "                        7.9833e-02,  1.7582e-02, -1.8942e-01,  6.9770e-02,  2.1733e-01],\n",
       "                      [-6.7660e-02, -9.0283e-02, -6.4724e-02,  1.5538e-01, -9.1371e-02,\n",
       "                       -1.2540e-01,  2.1092e-02, -2.7519e-01,  9.9500e-02,  3.9220e-01,\n",
       "                        3.1463e-01,  7.8011e-02,  6.9609e-02, -1.7158e-01, -4.1072e-02,\n",
       "                       -2.8598e-01, -2.1233e-01, -5.3522e-03,  1.3415e-01, -2.7277e-01,\n",
       "                       -1.6976e-01, -4.8485e-01, -6.0589e-01,  1.2095e-01,  5.1550e-02,\n",
       "                       -4.0458e-01,  3.2478e-02,  9.9034e-02,  2.2428e-01,  3.9812e-01,\n",
       "                        1.1167e-01, -2.1402e-01, -7.2445e-02, -2.4000e-01,  2.1914e-01,\n",
       "                       -3.3290e-01, -5.8020e-02, -4.4084e-01,  2.4338e-01, -4.0910e-02],\n",
       "                      [-1.0719e-01, -2.5084e-01,  1.9626e-01, -3.5578e-01,  1.1401e-01,\n",
       "                       -1.7291e-01,  3.0926e-01,  4.1851e-02,  2.0901e-01,  2.8857e-01,\n",
       "                       -3.5305e-01,  2.5265e-01,  2.3730e-02, -3.4233e-01, -1.4489e-01,\n",
       "                        4.2436e-02, -8.3095e-02, -6.7144e-02,  4.9233e-01,  3.9333e-01,\n",
       "                        1.3139e-01, -2.6733e-01, -1.6323e-01, -4.6614e-01,  1.7907e-01,\n",
       "                        5.6787e-02,  2.7718e-01, -4.2231e-01,  4.9355e-01, -2.4129e-01,\n",
       "                       -1.6363e-02,  3.4693e-01,  3.2214e-01,  2.1527e-01, -2.5099e-01,\n",
       "                        1.6499e-01,  1.9741e-01, -8.8927e-03,  1.4511e-01, -1.5059e-02],\n",
       "                      [ 1.6000e-01, -8.4653e-02, -4.6015e-02,  1.3219e-01, -5.1631e-01,\n",
       "                       -5.3368e-02, -2.0309e-01,  1.4004e-01, -2.7516e-01, -2.8502e-01,\n",
       "                        3.6906e-01, -1.4344e-01, -5.7948e-02, -7.5311e-03,  1.4710e-01,\n",
       "                        2.0854e-01,  4.9843e-02, -2.5899e-01, -2.9568e-01,  2.8047e-02,\n",
       "                        2.7102e-01,  3.5704e-01,  1.4397e-01, -8.9934e-02, -2.6434e-01,\n",
       "                       -3.3565e-02, -2.3234e-01,  1.3953e-01, -1.1555e-01, -1.9115e-01,\n",
       "                       -2.3283e-01, -2.5162e-01, -1.2793e-02,  2.0827e-01,  6.3914e-02,\n",
       "                        1.4745e-01,  3.0038e-02,  6.0195e-02, -3.8523e-01, -5.8746e-02],\n",
       "                      [ 2.3964e-01,  1.1037e-01, -2.9174e-01,  2.6716e-01, -3.6853e-01,\n",
       "                        1.0706e-01, -3.9011e-01, -8.7942e-02, -1.9784e-01, -2.2878e-01,\n",
       "                        5.2916e-01, -3.6440e-01,  1.4513e-01,  3.3621e-01,  1.8255e-01,\n",
       "                       -1.5291e-01, -3.0490e-01,  3.9181e-01, -4.2942e-01, -3.4958e-01,\n",
       "                       -6.9983e-02,  2.2361e-01, -8.8852e-02,  2.0793e-01, -3.5245e-01,\n",
       "                        3.3857e-03, -1.4953e-01,  2.8501e-01, -3.8771e-01,  2.7703e-01,\n",
       "                       -1.6968e-01, -3.4486e-01, -3.5026e-01, -1.8348e-01,  1.7505e-01,\n",
       "                       -3.6042e-01, -1.7252e-02,  3.7803e-02, -1.6075e-01,  3.2229e-03],\n",
       "                      [-1.0530e-01,  8.7593e-02,  1.8210e-01,  6.1435e-02, -2.3655e-01,\n",
       "                        7.5192e-02,  2.6477e-02, -4.3953e-02,  2.5752e-01,  2.0573e-01,\n",
       "                        3.2360e-01,  1.2928e-01, -3.2138e-01,  1.1584e-02,  5.7324e-02,\n",
       "                       -3.6747e-01,  6.0516e-02, -2.4535e-01,  2.2422e-01,  1.4889e-01,\n",
       "                       -1.0255e-01, -4.0287e-01,  4.1748e-01,  9.8464e-02, -8.1868e-02,\n",
       "                       -4.2062e-02, -1.6113e-01,  3.5040e-01, -1.4391e-01, -4.4932e-01,\n",
       "                       -5.7947e-01, -6.9524e-02, -3.5705e-02,  3.4210e-01, -1.9949e-02,\n",
       "                        2.6503e-01, -9.0306e-02,  6.0387e-01,  5.9823e-02,  2.1565e-01],\n",
       "                      [-9.5190e-02, -2.0213e-01,  4.2407e-02, -1.6164e-01,  3.2928e-01,\n",
       "                       -1.7843e-01,  4.8279e-01,  2.3103e-01, -1.4121e-01,  1.0346e-01,\n",
       "                       -2.7519e-01,  3.7677e-01, -1.3387e-01, -2.3926e-01,  2.2504e-01,\n",
       "                        1.2730e-01,  1.2944e-02, -8.6902e-02,  2.5966e-01,  4.6217e-01,\n",
       "                        2.8517e-02,  1.6750e-01,  3.4973e-01, -3.5421e-01,  1.1486e-01,\n",
       "                        1.8613e-01, -1.1219e-01, -1.8689e-01,  5.6441e-01, -5.1499e-01,\n",
       "                        3.6866e-01,  1.7618e-01,  4.0194e-01,  2.6859e-01, -4.0771e-01,\n",
       "                        3.5377e-01,  1.4664e-01,  7.1072e-03,  6.4113e-02,  8.2602e-02],\n",
       "                      [ 2.6112e-01,  6.5054e-03, -1.3946e-01,  1.9583e-01, -1.7549e-01,\n",
       "                        1.8758e-01, -3.6707e-01, -3.6477e-02, -1.6038e-01, -3.2498e-01,\n",
       "                        4.1581e-01, -5.2630e-01,  7.3238e-02,  3.3909e-01,  1.1527e-02,\n",
       "                        1.1770e-01,  4.2238e-02,  1.9278e-01, -2.4268e-01, -4.4840e-02,\n",
       "                        9.5541e-02,  2.3758e-01, -1.9050e-01,  3.5855e-01, -2.3888e-01,\n",
       "                        9.9608e-02, -7.4476e-02,  1.4333e-01, -3.4631e-01, -5.8422e-04,\n",
       "                       -3.9475e-01, -1.8294e-01, -9.8385e-02,  3.7835e-02,  2.4765e-01,\n",
       "                       -1.5092e-01, -2.1710e-01,  1.1281e-01, -5.3154e-02,  3.6291e-02],\n",
       "                      [ 2.4907e-01, -1.5125e-01, -4.8983e-02, -4.5346e-02, -5.1759e-01,\n",
       "                        2.5293e-01, -3.3757e-01, -2.9624e-01,  3.4192e-01,  4.4447e-01,\n",
       "                        2.8591e-01, -1.5904e-01,  2.2246e-01, -6.3702e-02, -7.1622e-02,\n",
       "                       -1.9327e-01, -3.7374e-02,  2.5620e-01,  2.5457e-01, -1.1543e-01,\n",
       "                       -3.2905e-01, -7.6611e-01, -5.4427e-01,  1.7207e-01,  9.5932e-02,\n",
       "                       -3.0251e-01,  1.3980e-01, -9.9017e-02,  1.2044e-01,  1.9705e-01,\n",
       "                       -1.5848e-01, -6.7872e-02,  3.0399e-02, -5.3121e-02,  2.0508e-01,\n",
       "                       -4.1691e-01, -1.3789e-01, -1.8661e-01,  3.6707e-01,  3.2730e-01],\n",
       "                      [-9.4525e-02, -3.7052e-02, -2.1210e-01,  1.6958e-02,  1.8686e-02,\n",
       "                        2.2841e-01, -2.7186e-02, -5.2528e-01,  4.0234e-01,  2.3932e-02,\n",
       "                        1.0269e-01,  8.4170e-02, -2.7942e-01,  1.5688e-01, -2.4646e-01,\n",
       "                       -1.8504e-01, -2.9430e-01,  2.4820e-01,  4.6673e-02, -4.7313e-01,\n",
       "                       -2.4877e-01, -3.8383e-01, -2.6989e-01,  3.5238e-01,  1.0738e-01,\n",
       "                       -1.3003e-01, -9.8986e-02,  2.4368e-01, -4.3488e-02,  4.2856e-01,\n",
       "                        1.0889e-02,  2.2486e-02, -3.4278e-01, -4.5874e-01,  1.4676e-01,\n",
       "                       -3.0166e-02, -2.6325e-01, -3.2802e-01,  3.6951e-01,  1.1762e-01],\n",
       "                      [ 3.1619e-01,  1.2905e-01, -2.0736e-01,  3.2983e-01, -6.5607e-02,\n",
       "                        1.0508e-01, -4.0870e-01,  6.1246e-02, -1.6049e-01, -6.5033e-02,\n",
       "                        3.0371e-01, -6.1025e-01,  9.2232e-02,  1.5623e-01,  1.7245e-01,\n",
       "                        3.3564e-02, -8.2569e-02,  2.4266e-01, -1.7501e-01, -2.0431e-03,\n",
       "                        1.6156e-03,  1.9087e-01,  7.3614e-02,  4.3035e-01, -6.0634e-02,\n",
       "                        1.7650e-01, -3.9173e-01,  1.5786e-01, -3.3745e-01, -2.1447e-01,\n",
       "                       -1.2982e-01, -2.9928e-01, -1.6394e-01, -1.0504e-01,  1.5603e-01,\n",
       "                       -1.6015e-01, -3.3252e-02,  2.0821e-01, -2.9658e-01, -2.0313e-01],\n",
       "                      [ 9.4584e-02, -2.8822e-01, -1.7511e-01, -3.7034e-02, -1.8623e-01,\n",
       "                        3.3892e-01,  1.7372e-01, -3.9592e-01,  3.7488e-01,  5.4031e-01,\n",
       "                        3.4747e-02, -1.8028e-01, -1.1415e-01, -1.4380e-01,  1.6517e-01,\n",
       "                       -2.6257e-01, -1.0363e-01, -9.3751e-03,  1.1643e-01, -8.5342e-02,\n",
       "                       -9.9519e-02, -2.7892e-01, -1.6968e-01,  4.6765e-02,  4.4848e-01,\n",
       "                       -4.2473e-01, -2.5374e-01, -1.1381e-01, -6.6076e-02, -2.5178e-01,\n",
       "                       -1.4670e-01,  2.0680e-01, -1.2650e-01,  2.6963e-04, -1.2568e-01,\n",
       "                        1.0918e-02, -7.9090e-02, -4.1558e-01,  3.7735e-01,  4.1563e-01],\n",
       "                      [ 6.7304e-02,  2.2131e-01, -2.8921e-01,  3.7788e-01, -2.2196e-01,\n",
       "                        3.6342e-02, -2.2839e-01, -4.7897e-02, -4.0811e-02, -3.9128e-01,\n",
       "                        3.9725e-01, -3.1074e-01, -6.6941e-02,  4.5804e-01,  8.8630e-02,\n",
       "                       -1.6156e-01,  1.1568e-01,  1.0011e-01, -2.2475e-01, -3.4671e-01,\n",
       "                        2.1230e-02,  2.4260e-01,  1.0644e-01,  3.3977e-01, -3.8217e-01,\n",
       "                        3.0129e-01, -3.1960e-01,  2.6612e-01, -2.7005e-01,  8.6873e-02,\n",
       "                        2.5806e-02, -1.2898e-01, -8.0886e-02,  3.3483e-02,  2.3835e-02,\n",
       "                        3.3269e-02, -1.5717e-01,  3.2130e-01, -1.5681e-01,  1.7994e-01],\n",
       "                      [ 2.9728e-02, -9.9189e-02, -4.5721e-01,  2.0607e-01, -1.7510e-01,\n",
       "                        8.6973e-02,  1.0676e-01, -4.4916e-01,  7.2926e-02,  2.3195e-01,\n",
       "                        3.3697e-01, -7.1269e-02, -2.5865e-01,  1.5332e-01,  1.0608e-01,\n",
       "                       -1.6189e-01, -1.1494e-01,  4.2038e-01,  1.3018e-01, -3.8695e-01,\n",
       "                       -3.5151e-01, -2.1110e-01, -5.8167e-01,  9.9872e-02,  2.8915e-01,\n",
       "                       -2.3340e-01, -2.9847e-01, -1.3107e-01, -1.1556e-01,  1.2469e-01,\n",
       "                        1.8325e-01, -5.2001e-02, -3.1520e-01, -3.8867e-01, -5.9657e-02,\n",
       "                       -2.4774e-01, -4.6912e-02, -4.4187e-01,  4.0404e-01,  1.4251e-01],\n",
       "                      [-1.9213e-01, -1.2305e-01, -4.6481e-01, -1.2308e-01, -1.3282e-01,\n",
       "                        2.6825e-02,  9.6047e-03, -4.8671e-01,  4.1358e-01,  7.5142e-02,\n",
       "                        1.9248e-01,  1.4341e-01, -3.5421e-01, -1.5431e-02, -1.0676e-01,\n",
       "                        6.0542e-03, -2.0145e-01,  2.3224e-01,  8.4175e-02, -3.8043e-01,\n",
       "                       -4.0799e-01, -3.5534e-01, -3.2729e-01,  2.9361e-02,  1.7089e-01,\n",
       "                       -2.4692e-01,  1.1836e-03, -7.5306e-02, -2.1344e-02,  8.5155e-02,\n",
       "                        2.0037e-01,  9.8240e-02, -1.4671e-01, -4.0560e-01, -1.5887e-02,\n",
       "                        4.3553e-02, -2.9086e-01, -3.6388e-01,  3.0606e-01,  2.2454e-01],\n",
       "                      [-1.2139e-01, -2.1422e-02,  2.1094e-01, -3.4152e-01,  2.4876e-01,\n",
       "                       -6.6457e-02,  2.7824e-01, -3.3116e-01,  5.0863e-01,  7.4280e-02,\n",
       "                       -2.1741e-01,  2.6729e-01, -8.0301e-02, -1.1901e-01, -5.0422e-01,\n",
       "                        2.7307e-01, -2.1022e-02,  1.0355e-01,  3.2268e-01, -1.4463e-02,\n",
       "                        3.3499e-02, -1.9675e-01,  5.5051e-02, -4.8828e-02,  3.3115e-01,\n",
       "                       -2.5885e-01, -1.1237e-01, -2.4612e-01,  1.2127e-01,  1.3087e-01,\n",
       "                        8.3069e-02,  2.2122e-01, -8.1968e-03,  3.5398e-02, -3.2569e-01,\n",
       "                        3.6073e-01, -1.1156e-01, -1.8372e-01,  2.3782e-01, -7.5008e-02]])),\n",
       "             ('classifier.0.bias',\n",
       "              tensor([ 0.0707, -0.0939,  0.0827,  0.0263,  0.0322, -0.0278, -0.0442, -0.2693,\n",
       "                      -0.1546, -0.0054,  0.1667, -0.1367, -0.1719, -0.0556, -0.1358, -0.0690,\n",
       "                      -0.0278, -0.1459, -0.0322, -0.0327])),\n",
       "             ('classifier.1.weight',\n",
       "              tensor([[ 6.0950e-02, -2.0561e-01, -2.1102e-01, -4.9321e-02,  1.3411e-01,\n",
       "                        3.7059e-02, -3.0644e-01,  2.5741e-02, -2.7107e-02, -1.9027e-01,\n",
       "                       -3.1756e-01, -3.1220e-02,  8.3005e-03, -2.1343e-01, -1.9107e-01,\n",
       "                        1.8260e-01, -9.7923e-02, -3.7886e-02, -1.0128e-01, -1.7339e-01],\n",
       "                      [ 7.8377e-02,  7.4641e-03,  4.4775e-01, -1.2953e-01,  9.8797e-02,\n",
       "                       -3.3914e-01,  2.8647e-01, -1.7465e-02, -8.2819e-03,  4.3800e-01,\n",
       "                        1.5907e-01,  6.6010e-02,  3.4644e-01, -1.3043e-01,  2.7728e-02,\n",
       "                        2.7848e-01, -2.1844e-01, -2.3230e-01, -1.5621e-01,  5.4481e-02],\n",
       "                      [-2.0248e-02, -2.8444e-01, -1.2855e-01,  1.6035e-02, -1.0577e-01,\n",
       "                       -9.4747e-02,  2.0421e-01, -2.5827e-01, -1.6516e-01,  7.7447e-02,\n",
       "                       -1.1840e-03,  1.9363e-01,  1.4218e-01, -1.8658e-02,  2.1314e-01,\n",
       "                       -1.0510e-01,  4.6044e-01, -5.7417e-02,  8.2870e-02,  1.2943e-01],\n",
       "                      [ 3.9675e-01, -2.1464e-01,  1.2169e-01, -2.0019e-02,  1.8838e-01,\n",
       "                        4.0316e-02, -1.2642e-01,  2.3045e-01,  1.1624e-01,  3.0032e-01,\n",
       "                       -3.2638e-01, -1.2501e-01, -7.9206e-02, -3.7894e-02, -7.8409e-02,\n",
       "                        1.1929e-02,  4.1571e-02, -2.5698e-01,  8.1555e-02,  2.0912e-02],\n",
       "                      [-6.4550e-02,  2.0845e-01,  3.1076e-01, -1.6093e-01, -1.1689e-01,\n",
       "                       -9.8049e-02,  9.7370e-02, -4.3217e-03,  1.0331e-01, -2.0051e-01,\n",
       "                        1.2084e-01, -3.9502e-02, -3.1359e-01, -1.2150e-01, -1.0577e-01,\n",
       "                        3.5738e-01, -2.0877e-01,  1.7676e-01,  1.8156e-01, -3.1925e-01],\n",
       "                      [ 2.0200e-01, -1.1452e-01,  1.9504e-01,  6.3911e-01, -4.4168e-02,\n",
       "                       -1.6219e-01,  3.4158e-01,  8.3339e-02, -3.4453e-01, -2.8846e-01,\n",
       "                        3.0278e-01, -2.9769e-02, -2.9099e-01,  8.2408e-02, -2.7124e-01,\n",
       "                        3.1292e-02, -1.6858e-01, -8.4143e-02, -1.2442e-01,  2.2834e-01],\n",
       "                      [-1.8274e-02, -2.8702e-01,  1.0484e-01,  8.1690e-01, -1.0307e-01,\n",
       "                        2.6551e-02, -4.4525e-02,  5.2210e-02, -4.1694e-01,  1.0279e-01,\n",
       "                        3.2470e-01, -1.1761e-03,  7.9490e-03, -3.2916e-01,  1.5684e-01,\n",
       "                       -5.1928e-02, -8.6524e-02, -1.0598e-01,  1.1924e-01,  1.3355e-01],\n",
       "                      [-1.9808e-01, -3.2902e-02, -2.1546e-01,  2.2001e-02, -6.5118e-02,\n",
       "                       -2.8905e-01,  3.8599e-02, -2.1684e-01, -4.0657e-02, -2.3067e-01,\n",
       "                       -3.7966e-02,  6.4901e-02,  1.9812e-01, -1.4588e-01, -2.5941e-01,\n",
       "                       -5.0783e-02,  1.9798e-01,  1.3670e-01,  4.8417e-02, -1.7138e-01],\n",
       "                      [ 8.4715e-02,  5.9511e-02, -1.4046e-01, -1.1380e-01, -2.2472e-01,\n",
       "                       -3.4490e-01,  7.2402e-02, -1.0313e-02, -1.8650e-01, -8.8571e-02,\n",
       "                        2.6677e-01,  7.9390e-03, -1.0742e-01, -1.2048e-01,  2.8446e-01,\n",
       "                        2.8354e-02,  2.5030e-01,  3.8264e-01,  8.1007e-02,  1.6493e-01],\n",
       "                      [-1.4118e-01, -1.4006e-01, -1.3707e-01,  4.3706e-01,  1.3040e-01,\n",
       "                        1.0246e-01,  3.5932e-01,  2.9851e-01,  1.3509e-01,  1.9380e-02,\n",
       "                       -6.1887e-02,  1.0181e-01,  6.0229e-01, -1.3911e-02, -3.0926e-02,\n",
       "                        5.6742e-01, -3.7354e-02,  4.9918e-01, -6.5711e-02, -1.3564e-01],\n",
       "                      [ 2.5075e-01, -2.9596e-02,  3.0200e-01,  3.6513e-02,  1.1843e-01,\n",
       "                       -2.8924e-02,  2.1384e-01, -2.7743e-01,  1.6396e-01,  1.4679e-01,\n",
       "                        3.4026e-02, -4.1037e-02,  7.5626e-02,  3.4280e-02,  1.9619e-01,\n",
       "                       -3.5373e-01,  2.5821e-01,  7.8940e-02, -1.9664e-03,  2.4376e-01],\n",
       "                      [-1.7277e-02,  1.3945e-01,  1.5483e-01, -7.0926e-01, -1.2102e-02,\n",
       "                        1.6441e-01, -1.3186e-01, -1.9591e-01,  1.7975e-01,  3.2047e-01,\n",
       "                       -9.3107e-02, -1.5373e-01,  2.6636e-01, -8.8651e-04,  4.5458e-02,\n",
       "                        2.1154e-01, -1.9798e-02,  4.5516e-02, -1.4976e-01,  2.0824e-02],\n",
       "                      [-2.2523e-01, -2.8922e-01,  3.3653e-01,  1.7008e-01, -1.3493e-02,\n",
       "                       -7.3385e-02, -2.8979e-01,  2.5235e-01,  4.0183e-02,  3.8278e-01,\n",
       "                       -3.8315e-01,  1.2279e-01, -7.5192e-02,  2.2944e-01,  1.9747e-02,\n",
       "                        3.5842e-01, -8.3540e-02, -2.8593e-01,  8.3479e-02,  2.4297e-01],\n",
       "                      [-1.9428e-01, -1.5782e-01, -3.1114e-01, -7.3133e-02,  9.0182e-03,\n",
       "                       -5.3925e-02,  2.1625e-01, -2.8252e-02,  3.6038e-02, -2.6423e-01,\n",
       "                       -3.7181e-02, -1.7306e-02, -1.4633e-01, -1.2895e-01, -2.1775e-01,\n",
       "                       -8.8964e-02, -5.3553e-02,  4.0856e-02, -9.7728e-02, -1.7135e-01],\n",
       "                      [ 8.4460e-02,  2.2839e-01, -1.9418e-01, -4.8743e-02,  2.0205e-02,\n",
       "                       -9.6025e-02, -8.9979e-02,  3.3226e-02,  5.9384e-03, -1.6316e-01,\n",
       "                        9.4651e-02, -1.6244e-01,  1.5296e-01, -7.6235e-02,  1.0774e-02,\n",
       "                       -9.9091e-02,  8.7122e-02, -7.1888e-02, -1.4127e-01,  3.6193e-01],\n",
       "                      [-7.9258e-02,  4.0566e-01,  2.7264e-01, -7.2402e-01,  7.3889e-02,\n",
       "                        9.1184e-02, -2.0211e-01, -1.5946e-02,  3.7565e-02,  3.1329e-01,\n",
       "                       -4.4896e-01,  2.6156e-01, -8.2826e-02,  2.3826e-01, -1.7341e-02,\n",
       "                        8.8491e-02,  2.3795e-01,  1.8092e-01,  3.2854e-02,  2.3486e-02],\n",
       "                      [-2.4842e-01,  4.4595e-01,  2.0868e-01, -1.3718e-01, -2.3292e-01,\n",
       "                       -1.6931e-01, -6.0655e-02,  1.8455e-01,  3.9305e-01, -1.2551e-01,\n",
       "                       -2.2536e-01,  3.3443e-01, -1.8046e-01,  3.8550e-02,  2.1101e-01,\n",
       "                       -1.4709e-01,  2.6633e-01, -1.0973e-01, -3.9767e-01, -2.1903e-01],\n",
       "                      [ 4.1889e-02, -8.1780e-02,  2.1480e-04, -8.7777e-02, -1.1859e-01,\n",
       "                       -7.2366e-02, -5.1936e-02, -8.4550e-02,  2.4973e-01, -3.9406e-01,\n",
       "                       -1.5189e-01,  2.3550e-01,  1.5421e-01, -2.7314e-02,  1.0836e-01,\n",
       "                        1.3475e-01, -4.3589e-02,  1.9005e-01,  1.1995e-01,  2.0895e-01],\n",
       "                      [-1.0435e-01,  4.0363e-03,  9.4120e-02,  6.1267e-01,  2.3604e-01,\n",
       "                       -2.6642e-01,  1.7843e-01, -1.0554e-01, -3.4361e-01,  6.0193e-02,\n",
       "                        2.5701e-01,  2.9100e-02, -2.2701e-01, -2.5381e-01,  2.7467e-01,\n",
       "                        1.5957e-01, -1.0971e-01, -1.3541e-01, -1.5323e-01,  1.1915e-01],\n",
       "                      [-2.0713e-01,  2.9124e-02,  5.5842e-01, -4.3733e-02, -1.5036e-01,\n",
       "                       -1.9537e-01,  2.8447e-01,  8.2283e-02, -6.6738e-02, -4.6146e-01,\n",
       "                       -1.2479e-01,  7.9704e-02,  9.0250e-02,  1.3758e-01,  1.4444e-01,\n",
       "                       -9.3824e-02, -1.0135e-01,  8.8545e-02,  9.6452e-02,  2.7907e-01],\n",
       "                      [ 1.1497e-01, -1.0929e-01, -8.9528e-02, -4.8917e-02,  1.2691e-01,\n",
       "                        1.3203e-01, -1.1081e-01,  1.4723e-02, -9.8952e-02,  1.1647e-01,\n",
       "                       -2.5465e-02, -1.1939e-01, -7.2428e-02,  3.5208e-01,  6.4228e-02,\n",
       "                        7.4813e-03, -4.3056e-02,  1.6123e-01,  2.4906e-01,  2.1656e-01],\n",
       "                      [-5.2165e-01,  1.8700e-01,  1.1742e-01, -1.6236e-01,  1.4405e-01,\n",
       "                       -3.8808e-01, -1.2706e-01,  1.8268e-01,  3.3963e-02,  2.7697e-02,\n",
       "                        4.3640e-01, -3.7962e-02, -2.8270e-01,  1.4811e-01,  9.9377e-04,\n",
       "                        4.4776e-01,  1.8666e-01,  2.4015e-01,  8.3573e-02,  7.6036e-02],\n",
       "                      [ 7.4738e-02,  1.3450e-01,  6.6955e-03,  2.0743e-01, -1.8292e-01,\n",
       "                       -4.1818e-01,  2.8555e-02,  2.8980e-01, -1.8456e-01,  3.5475e-01,\n",
       "                       -4.8566e-02,  1.3381e-01,  1.1650e-01,  9.0115e-02, -3.7590e-01,\n",
       "                       -9.6169e-02,  4.6673e-01, -2.7197e-02,  3.6196e-01,  1.5868e-01],\n",
       "                      [-1.9548e-01, -6.9419e-02,  2.9048e-01, -3.0285e-02, -1.4966e-01,\n",
       "                       -1.4071e-01, -2.4470e-01,  6.6527e-02,  3.0599e-01, -3.8405e-01,\n",
       "                       -3.2284e-01,  2.0182e-02,  1.2785e-01,  4.2165e-02,  1.2934e-01,\n",
       "                        2.6449e-01,  1.4755e-02,  2.5597e-01, -2.0489e-01,  2.6773e-01],\n",
       "                      [-2.6555e-02,  3.1807e-01, -6.4443e-03, -3.3813e-01,  3.3844e-02,\n",
       "                       -7.8879e-02, -1.6849e-01,  2.7292e-01,  2.9612e-01, -1.3485e-01,\n",
       "                       -3.7578e-01,  1.9025e-01,  1.8120e-01, -1.8535e-02,  2.7032e-01,\n",
       "                       -3.5599e-01, -5.3634e-02, -4.6252e-02,  1.2895e-01,  2.0079e-01],\n",
       "                      [ 2.5164e-01,  3.5660e-02, -7.4129e-02,  3.3936e-01,  3.2478e-02,\n",
       "                        1.6686e-01,  3.0855e-01,  3.0359e-01,  1.7557e-01,  6.4905e-02,\n",
       "                       -1.5083e-01, -5.3386e-02,  7.1437e-01, -1.9464e-01,  7.4859e-02,\n",
       "                        1.3157e-01, -5.2641e-02, -6.6831e-02,  1.0769e-01, -2.0553e-01],\n",
       "                      [ 3.7144e-02,  1.5097e-01,  1.9545e-01,  3.6247e-01, -7.6082e-03,\n",
       "                       -1.0515e-01, -3.2187e-01,  4.1509e-02,  2.6679e-01,  1.2873e-01,\n",
       "                        2.2099e-02, -9.2148e-02, -3.0340e-01, -4.9609e-01,  2.5808e-01,\n",
       "                       -1.7354e-01,  1.6951e-01, -3.4863e-01, -2.6140e-01, -3.4277e-01],\n",
       "                      [-4.1801e-01, -5.9226e-02, -8.5443e-03,  2.7978e-01,  2.8395e-01,\n",
       "                        2.2498e-01, -3.6411e-01, -1.0698e-01, -1.7313e-01,  2.8933e-01,\n",
       "                       -4.6979e-03, -2.5782e-01, -8.1506e-02,  4.8621e-03,  2.8838e-01,\n",
       "                        3.7818e-01,  2.4053e-01, -7.8820e-02, -2.5134e-01,  1.6732e-01],\n",
       "                      [-1.9801e-01,  7.6712e-02,  3.3872e-01, -2.7481e-01,  1.3522e-01,\n",
       "                       -6.5024e-02,  7.1995e-02, -2.7046e-01, -3.0368e-01,  1.9867e-01,\n",
       "                        9.1708e-02, -1.6721e-01,  1.7847e-01,  1.6387e-01, -1.4632e-01,\n",
       "                        2.2162e-01, -1.5208e-01,  8.8632e-02,  1.7730e-01,  5.8951e-02],\n",
       "                      [ 1.5775e-01, -2.9785e-02, -1.5402e-01,  1.1521e-01, -1.6792e-01,\n",
       "                        2.6215e-02,  1.2266e-01, -2.6404e-01, -2.8397e-01,  4.9826e-02,\n",
       "                       -2.2505e-02, -6.6293e-02,  2.5700e-01, -5.9166e-02, -2.1560e-01,\n",
       "                        7.0674e-02,  3.6978e-01, -2.1496e-01, -1.0738e-01, -2.0228e-01],\n",
       "                      [ 4.8319e-02,  1.6578e-01,  3.9904e-02, -6.3408e-01, -3.6872e-02,\n",
       "                       -8.5650e-02, -2.4261e-01, -2.4441e-02,  5.1749e-01, -2.4083e-01,\n",
       "                       -3.1444e-02,  1.0237e-02,  1.9672e-01, -9.8222e-02,  1.8914e-01,\n",
       "                        1.3726e-01,  1.9499e-01,  3.5634e-01,  1.4642e-01, -5.2905e-02],\n",
       "                      [-1.5491e-01,  1.5301e-01,  3.4622e-01,  2.4767e-01,  4.0448e-02,\n",
       "                        2.1908e-02, -1.3834e-01, -2.1072e-02, -1.8630e-02, -1.0458e-01,\n",
       "                       -1.8932e-01,  8.9450e-02, -1.8296e-01,  8.4308e-02,  1.1577e-01,\n",
       "                        1.8739e-01, -4.9709e-02,  1.8056e-02,  1.8609e-01,  1.8287e-01],\n",
       "                      [-1.2006e-02, -1.8856e-01, -3.7834e-01,  2.9672e-02,  4.4542e-02,\n",
       "                        5.9052e-01, -9.8905e-02,  1.1335e-01,  2.7134e-01,  4.1025e-02,\n",
       "                        2.3866e-01, -2.4733e-01,  3.8008e-03, -2.2430e-01,  1.0833e-01,\n",
       "                       -3.7997e-01, -4.8726e-02,  2.5634e-01, -6.8642e-02, -1.2693e-01],\n",
       "                      [-7.4942e-02, -3.5769e-01, -1.1883e-01,  6.4170e-01,  1.2305e-01,\n",
       "                        5.6305e-02,  6.2878e-02, -5.8529e-02, -1.1340e-01, -7.4164e-02,\n",
       "                       -1.0041e-01, -7.4535e-02, -1.2362e-01, -1.7313e-01,  3.4624e-02,\n",
       "                       -4.7774e-02, -1.1451e-01,  2.3947e-01, -3.7918e-02,  8.2958e-02],\n",
       "                      [ 3.8092e-01, -2.2477e-01,  2.8454e-01, -4.8268e-02, -1.8478e-01,\n",
       "                       -6.0347e-02,  3.8244e-02, -3.7659e-01, -3.6497e-01, -1.9778e-01,\n",
       "                       -2.9376e-01, -8.9778e-02,  1.1898e-01, -1.0749e-01, -1.8105e-01,\n",
       "                       -2.3864e-01,  1.2914e-01, -1.8655e-01, -4.5294e-02,  1.2849e-01],\n",
       "                      [ 2.2069e-02, -2.7628e-01, -8.9822e-02,  6.9281e-02, -1.0686e-01,\n",
       "                       -6.5492e-02, -5.5905e-02, -3.0172e-01, -1.9158e-01, -2.2089e-01,\n",
       "                        5.3708e-02, -1.1768e-01, -1.4421e-01,  3.0422e-01, -2.8354e-01,\n",
       "                        1.0584e-01, -5.4406e-02,  3.9173e-02,  2.2172e-02, -7.7408e-02],\n",
       "                      [ 3.1109e-01,  1.7662e-01, -2.0404e-01, -1.5409e-01,  8.7192e-02,\n",
       "                       -6.7450e-02,  2.8086e-01,  3.0559e-01,  4.2007e-01,  1.2078e-01,\n",
       "                        2.6755e-01,  4.3313e-02, -2.0660e-01,  8.1879e-02, -8.3992e-02,\n",
       "                       -1.3095e-01, -5.3748e-03, -1.5650e-01,  6.8554e-02,  1.5363e-01],\n",
       "                      [ 2.3637e-02, -3.2376e-01,  5.9048e-02,  5.4119e-01,  1.7716e-02,\n",
       "                       -5.6988e-02,  1.6041e-01,  1.8866e-01, -3.2683e-01,  3.5897e-01,\n",
       "                       -8.5715e-03,  7.6715e-02, -8.8230e-02, -9.4129e-02, -2.2845e-01,\n",
       "                       -1.2056e-01,  2.9365e-01,  3.6289e-02, -2.0540e-01,  1.0988e-01],\n",
       "                      [ 2.1440e-01, -3.1536e-01,  5.5699e-01, -7.0121e-02, -1.5525e-01,\n",
       "                        1.9553e-01,  7.4612e-02, -2.2211e-01, -1.1018e-01, -1.5494e-01,\n",
       "                       -4.5820e-01, -4.4522e-02,  3.1681e-01,  7.2973e-02,  1.0200e-01,\n",
       "                       -3.7997e-02, -3.5019e-01, -3.3061e-01, -1.4547e-01, -9.8176e-02],\n",
       "                      [ 2.6785e-01,  2.2557e-01, -6.3862e-03, -8.6977e-02, -1.1627e-01,\n",
       "                        1.8746e-02, -1.2290e-02,  3.0322e-01,  3.0985e-01,  1.1387e-01,\n",
       "                       -8.2845e-03, -1.0230e-01, -2.1814e-01,  1.8547e-02, -1.0192e-01,\n",
       "                       -3.1672e-03, -2.9645e-01, -7.2383e-02,  5.2050e-02,  1.9379e-01]])),\n",
       "             ('classifier.1.bias',\n",
       "              tensor([ 1.0543e-02,  1.8218e-01,  1.8998e-02, -7.4502e-02,  1.1545e-01,\n",
       "                       1.3342e-01,  7.6650e-02,  6.4938e-02,  7.6520e-02, -6.3966e-02,\n",
       "                      -1.0239e-02,  3.6293e-05, -2.0348e-01,  1.9767e-01,  6.6641e-02,\n",
       "                      -1.3917e-01,  2.5831e-01, -2.3847e-01,  2.2735e-01, -5.6861e-02,\n",
       "                      -2.5227e-01,  3.0675e-02, -9.0176e-02, -2.0740e-01, -1.1849e-01,\n",
       "                      -8.0195e-02,  1.9063e-01, -6.5748e-02,  1.9515e-02,  7.8021e-02,\n",
       "                       3.0627e-02, -1.0135e-01, -5.2987e-02,  3.0381e-02, -1.3446e-02,\n",
       "                      -1.8212e-01,  7.9845e-03, -1.0309e-02, -6.3297e-03, -2.6675e-02])),\n",
       "             ('classifier.2.weight',\n",
       "              tensor([[ 1.0113e-01,  3.3481e-01,  1.3641e-01,  1.6435e-01, -2.8515e-02,\n",
       "                       -7.7061e-02,  6.6029e-02, -1.4357e-01,  2.8175e-02,  5.1141e-03,\n",
       "                        1.0143e-01,  1.3182e-01, -1.7105e-02,  1.3601e-01,  1.2406e-02,\n",
       "                        4.7514e-02,  3.3228e-01, -1.7403e-01,  2.4238e-01, -4.6444e-02,\n",
       "                       -2.6519e-01, -1.6838e-01, -1.0369e-01, -1.3583e-01, -9.8555e-02,\n",
       "                       -1.5234e-02,  2.4433e-01, -1.6818e-01, -1.0873e-01,  1.1766e-01,\n",
       "                        1.7215e-01, -3.1945e-01,  8.4543e-02, -4.8445e-02,  2.0264e-01,\n",
       "                       -1.5585e-01, -2.6116e-02,  9.2789e-02,  3.5836e-01,  9.7903e-02],\n",
       "                      [ 2.8089e-01, -2.3934e-01, -2.0675e-02,  9.7548e-02, -2.6184e-01,\n",
       "                       -1.4040e-01,  4.9955e-02,  7.7066e-03, -9.7932e-03,  2.5140e-01,\n",
       "                       -1.1529e-01,  1.7705e-02,  1.1637e-01,  4.3389e-02,  2.2166e-02,\n",
       "                        5.7902e-02,  1.2061e-01,  1.2728e-01,  1.6547e-02, -1.6499e-01,\n",
       "                        9.0222e-02, -4.0679e-02,  1.7310e-02,  1.2469e-01, -4.4653e-02,\n",
       "                        1.4120e-04, -2.1457e-03,  3.3365e-01, -9.1916e-02,  2.6944e-01,\n",
       "                       -1.5141e-01, -1.3771e-02, -5.3310e-02,  1.2497e-01,  1.1349e-01,\n",
       "                        5.3074e-02, -3.8988e-01,  8.1222e-02,  2.0755e-01, -8.7645e-02],\n",
       "                      [-1.3289e-02,  1.6584e-01,  3.1053e-01,  2.3997e-01, -6.2791e-02,\n",
       "                       -2.2971e-01,  4.7121e-02,  2.2660e-01, -1.6455e-02, -4.5804e-02,\n",
       "                        4.2565e-02, -9.6591e-02,  2.5128e-01, -8.2171e-03, -1.2726e-01,\n",
       "                        1.5694e-01,  3.1182e-02, -1.5470e-01, -1.1591e-01, -3.3908e-01,\n",
       "                        8.9660e-03,  6.5537e-03,  6.3576e-01, -9.9672e-02, -1.4722e-02,\n",
       "                        7.9173e-02,  4.4178e-02,  3.6129e-02, -5.1446e-03,  2.4897e-01,\n",
       "                       -2.3348e-01, -1.3583e-01, -1.5121e-01, -1.9969e-01,  2.7986e-02,\n",
       "                       -1.2557e-01,  7.5557e-02,  4.9392e-01, -1.1560e-01, -1.6290e-01],\n",
       "                      [ 4.4290e-02,  1.0803e-01, -2.9228e-02,  7.0197e-02, -8.6390e-02,\n",
       "                       -1.3944e-01,  4.1547e-02, -1.8089e-01, -9.8010e-02,  2.6193e-02,\n",
       "                       -1.2330e-02, -1.5339e-01,  2.9607e-01, -1.7325e-01,  1.0217e-01,\n",
       "                        2.8202e-02,  3.4258e-01, -7.8543e-03, -8.1433e-03,  1.2958e-01,\n",
       "                       -4.3876e-03, -6.3276e-03,  6.1259e-02,  2.3117e-01,  1.9459e-01,\n",
       "                        4.3411e-02,  2.8322e-01,  2.9367e-01, -2.3184e-01, -1.6314e-01,\n",
       "                       -5.6190e-02,  2.1002e-01, -1.8297e-01,  1.6162e-01, -2.0180e-01,\n",
       "                       -1.8367e-01, -8.8222e-02,  1.9009e-01,  2.0786e-02,  1.0409e-02],\n",
       "                      [-4.7193e-02,  3.4206e-01,  3.3265e-01, -5.0582e-01, -3.5645e-02,\n",
       "                        8.9715e-02,  1.8839e-02,  2.6582e-01,  4.1366e-01, -1.7626e-01,\n",
       "                        3.6119e-02,  2.6192e-01, -4.4138e-01,  7.5561e-03,  1.3686e-01,\n",
       "                       -7.3503e-02,  5.4416e-02,  1.5296e-02,  2.8579e-01,  2.1086e-01,\n",
       "                       -2.5170e-01,  2.1480e-01, -2.3594e-01,  7.9143e-02, -1.3784e-01,\n",
       "                       -2.7889e-01, -2.5182e-01,  4.7714e-02,  3.5796e-01,  2.4690e-01,\n",
       "                        2.3297e-01,  1.2185e-02, -4.1791e-01, -3.1384e-01,  2.1576e-01,\n",
       "                       -4.5781e-02, -3.4483e-01, -1.7782e-01,  1.3448e-01, -4.8559e-01],\n",
       "                      [-1.2983e-01,  1.9917e-01, -1.8869e-01,  5.2762e-02,  2.1346e-01,\n",
       "                        2.8959e-01,  1.4140e-01, -1.7254e-01,  1.2179e-02,  5.1519e-02,\n",
       "                       -3.8617e-02, -8.3160e-02,  2.8366e-02, -5.2792e-02, -6.5467e-02,\n",
       "                       -5.3216e-02, -1.4310e-01, -1.1559e-01,  3.0755e-01,  5.9148e-02,\n",
       "                        1.0710e-01,  2.4671e-01,  1.3142e-01, -7.6602e-03, -1.8891e-01,\n",
       "                       -9.4054e-02,  1.3221e-01,  8.1342e-02, -1.5465e-02, -6.9172e-02,\n",
       "                       -2.5458e-01,  1.1293e-01, -1.6330e-01, -5.3644e-02, -2.2519e-01,\n",
       "                       -5.8624e-02,  9.4241e-02,  3.5357e-02, -7.5149e-02,  2.0088e-01],\n",
       "                      [-2.4679e-02,  1.6152e-01, -3.8003e-02,  1.4771e-01, -2.3997e-02,\n",
       "                        1.0900e-01, -2.2024e-03, -1.6962e-01,  1.1521e-01,  1.9014e-01,\n",
       "                       -1.2087e-01, -2.4684e-02,  3.5386e-01, -1.5306e-01, -8.7165e-02,\n",
       "                        4.9339e-02, -3.6260e-01,  1.4788e-01, -7.8386e-02,  2.9732e-01,\n",
       "                        2.9357e-01,  2.5078e-01,  3.2906e-01,  1.6092e-01, -1.4235e-01,\n",
       "                       -2.5607e-02, -4.6953e-01, -5.2452e-02,  1.2499e-01, -1.1129e-01,\n",
       "                       -1.5410e-02, -2.7788e-03, -3.3997e-01,  1.9066e-02,  3.0062e-02,\n",
       "                        2.4376e-01,  1.9973e-01, -6.4487e-02,  1.7200e-02,  1.6984e-01],\n",
       "                      [ 7.1003e-02,  1.9368e-01, -2.0406e-01,  4.0240e-02,  4.9898e-01,\n",
       "                        8.7783e-02, -1.1573e-01,  7.3885e-02, -1.2214e-01,  1.4491e-01,\n",
       "                       -9.0225e-03, -5.6638e-02, -2.9282e-01,  1.3101e-01, -2.1420e-02,\n",
       "                       -2.4771e-01,  1.0678e-01,  2.0947e-01, -5.3626e-02,  2.1104e-01,\n",
       "                       -1.6627e-01, -2.3570e-01, -3.1429e-01,  8.0750e-02,  6.2491e-02,\n",
       "                        2.4403e-01,  4.5712e-02, -4.8435e-01, -5.4915e-02,  1.0308e-01,\n",
       "                        7.2816e-02, -1.3355e-01, -3.2620e-02, -2.1318e-01,  1.4920e-01,\n",
       "                       -1.0027e-01,  4.2168e-02, -2.7073e-01,  5.2392e-01,  5.5252e-02],\n",
       "                      [ 2.0378e-02,  3.1535e-01, -4.1907e-02,  1.3248e-01, -1.0173e-01,\n",
       "                       -1.3683e-01,  6.9664e-02,  2.5505e-03,  1.7968e-01,  5.2098e-01,\n",
       "                       -7.3290e-02,  2.6303e-01,  5.6052e-02,  1.0258e-03, -4.5678e-02,\n",
       "                       -5.1457e-02, -1.9984e-01, -1.1385e-01, -2.1644e-03, -1.8724e-01,\n",
       "                        2.5531e-03,  5.8238e-02,  5.2466e-02, -2.6270e-01, -1.9192e-01,\n",
       "                        4.2282e-01, -8.6923e-02,  2.3480e-01,  2.0582e-01,  1.4493e-01,\n",
       "                        1.1967e-01, -1.0486e-01,  2.2717e-01, -2.4634e-02, -2.7513e-01,\n",
       "                       -1.5953e-01,  1.4945e-02,  9.1589e-02, -2.2729e-02, -7.6505e-02],\n",
       "                      [-6.0252e-02, -3.0857e-01,  3.0877e-01, -9.9458e-02, -2.3043e-01,\n",
       "                       -2.6400e-03,  2.2686e-02,  4.2184e-02,  2.5344e-01,  3.6430e-01,\n",
       "                        1.6116e-01, -3.1604e-01, -2.3176e-01,  3.3113e-04,  2.0128e-01,\n",
       "                       -1.3664e-01, -2.9931e-02,  2.6511e-01, -9.7750e-02,  6.8288e-02,\n",
       "                        5.1078e-02, -1.3628e-01,  3.9099e-01,  1.3003e-01,  3.4195e-01,\n",
       "                        2.0932e-01, -2.6676e-01, -4.8560e-01, -2.7758e-01,  1.0250e-01,\n",
       "                        1.9204e-01,  1.3052e-02,  3.0683e-01,  6.7954e-02, -7.1869e-02,\n",
       "                       -1.2304e-01,  1.1426e-01,  1.7308e-01, -2.5207e-01,  1.4248e-01],\n",
       "                      [-8.0645e-02,  2.0963e-01,  3.3861e-02,  3.1370e-02,  2.9917e-01,\n",
       "                        1.3034e-01, -5.7506e-02,  3.1654e-02,  7.0124e-02, -2.8543e-02,\n",
       "                        1.8654e-01,  1.1441e-01, -6.9385e-02, -2.4294e-02, -6.8813e-02,\n",
       "                       -2.6234e-02,  1.1194e-01, -6.0128e-02,  1.5330e-01,  1.7340e-01,\n",
       "                       -1.2923e-01,  2.0671e-01,  2.8242e-01, -1.3765e-01,  1.2102e-01,\n",
       "                        1.3751e-01,  1.4626e-01, -6.0725e-01,  1.9641e-01,  2.6097e-02,\n",
       "                        6.8912e-02,  3.2842e-02, -3.1286e-01, -3.7967e-02, -8.1488e-03,\n",
       "                       -1.0716e-01,  2.1279e-01, -3.0104e-02, -7.3728e-02,  2.4175e-01],\n",
       "                      [ 1.8752e-01,  1.0129e-01, -9.6702e-02, -1.1323e-01,  7.0380e-03,\n",
       "                        6.7531e-02, -6.0074e-02,  3.1478e-01, -1.0727e-01, -7.0751e-02,\n",
       "                       -3.4337e-01,  3.5410e-02,  1.5535e-01,  8.9412e-02, -6.6964e-02,\n",
       "                        1.1062e-01, -1.1710e-01, -9.7376e-03, -2.0268e-01,  1.2842e-01,\n",
       "                       -2.2221e-01, -1.2676e-01,  2.4858e-01,  1.5146e-01,  2.1246e-01,\n",
       "                        1.1396e-01,  1.5158e-01, -1.4728e-01,  9.5162e-02,  1.4501e-01,\n",
       "                       -1.2963e-01,  1.5012e-01, -1.6087e-01, -1.0882e-01,  2.8611e-01,\n",
       "                        1.9134e-02, -2.6551e-01,  1.6708e-01,  3.5854e-01, -2.1017e-01],\n",
       "                      [-4.2038e-02, -8.0399e-02,  4.1934e-02,  5.8735e-02,  1.0101e-01,\n",
       "                       -4.3527e-01, -3.3322e-01, -1.5007e-01, -6.3704e-02, -7.3578e-02,\n",
       "                       -1.7233e-02,  3.0840e-01,  1.9251e-01, -2.3454e-01,  2.6981e-03,\n",
       "                        4.2554e-01,  1.8295e-01,  6.7091e-02, -1.0942e-01, -4.7789e-02,\n",
       "                       -3.2874e-02,  2.1601e-01,  1.0264e-02,  1.4403e-01,  3.0072e-01,\n",
       "                       -1.3963e-01, -1.3141e-01,  6.2591e-02,  1.1526e-01, -4.9935e-02,\n",
       "                        3.4308e-01,  3.7151e-02, -1.5747e-01, -3.1157e-01, -7.2157e-02,\n",
       "                        2.8140e-02, -7.7310e-02, -2.0314e-01, -6.0660e-02,  1.3285e-01],\n",
       "                      [-1.2453e-01,  5.0134e-02,  2.0477e-02, -1.2310e-01,  3.1772e-01,\n",
       "                       -2.0964e-02,  3.0354e-01,  3.2511e-02, -1.0898e-01,  3.9855e-01,\n",
       "                        9.6976e-02, -1.0293e-01,  2.8457e-01, -1.1831e-01, -8.4448e-02,\n",
       "                       -9.8073e-02, -1.7456e-01,  1.1494e-01,  2.8101e-01,  1.8638e-01,\n",
       "                        8.7836e-02,  3.4020e-01, -1.7584e-01,  2.8181e-01, -1.3094e-01,\n",
       "                        9.4452e-03, -2.0458e-02,  1.4197e-01,  1.9661e-01, -2.3598e-01,\n",
       "                        4.2291e-03,  2.5459e-01, -1.6012e-01,  2.4735e-01, -9.0584e-02,\n",
       "                       -3.0255e-02, -3.3184e-01,  1.4894e-01,  6.4987e-02, -1.1299e-01],\n",
       "                      [ 1.4902e-01, -1.1319e-01,  8.1038e-02,  1.4698e-01,  1.5837e-01,\n",
       "                        2.5929e-02, -2.7242e-01, -1.1112e-01, -1.3018e-01, -2.9056e-01,\n",
       "                        1.0185e-01,  1.4251e-01, -5.7488e-02,  8.9596e-02, -8.1494e-02,\n",
       "                        1.0264e-01, -4.4183e-01, -1.4436e-01, -1.7399e-01, -2.4513e-01,\n",
       "                        2.9962e-01, -1.4996e-02, -9.1669e-02, -2.6357e-01, -3.0072e-01,\n",
       "                       -4.2051e-01, -4.0886e-01, -8.6010e-02,  3.2813e-01,  1.7179e-01,\n",
       "                       -1.5808e-01, -4.3033e-02,  7.7991e-02,  2.8684e-02,  2.7424e-01,\n",
       "                        3.7760e-01, -1.3676e-01,  9.1038e-02,  1.2954e-01,  9.5170e-02],\n",
       "                      [ 3.5377e-01, -3.3209e-01, -5.7412e-03, -1.8281e-01,  3.0560e-01,\n",
       "                       -9.9350e-02,  7.8356e-03,  3.4225e-01,  7.5502e-02,  1.9828e-01,\n",
       "                       -3.9036e-01, -2.0727e-01, -3.3012e-02,  2.9288e-01, -3.5146e-02,\n",
       "                       -1.8389e-01, -2.8550e-02,  9.9042e-02,  9.8436e-03, -1.5845e-01,\n",
       "                       -1.1221e-01,  4.8533e-01, -2.0660e-02,  1.5527e-01, -1.4737e-01,\n",
       "                       -2.6425e-01,  1.3087e-01,  7.4078e-02, -1.7480e-01, -5.0456e-02,\n",
       "                        2.5440e-01, -7.2713e-02,  8.2295e-02,  4.2165e-02, -2.5241e-01,\n",
       "                        1.7972e-01, -2.0525e-01,  1.6048e-02, -4.7906e-01, -2.4203e-01],\n",
       "                      [-1.3512e-02,  2.4084e-01, -2.0696e-01, -1.0593e-01,  1.3960e-01,\n",
       "                       -1.5751e-01, -2.1545e-01, -2.1735e-02, -9.8075e-02,  1.1436e-01,\n",
       "                       -2.8947e-01,  1.6032e-01, -2.8827e-01,  1.6624e-01,  1.3386e-01,\n",
       "                       -4.8530e-02, -8.2188e-02, -3.3454e-01, -1.1170e-01, -3.4124e-01,\n",
       "                       -1.2172e-01,  1.4385e-01,  4.9678e-02, -4.6389e-01, -1.9135e-01,\n",
       "                       -8.3988e-03,  1.0195e-01, -7.9154e-02,  1.5980e-01,  2.1770e-01,\n",
       "                       -3.8141e-02, -3.0698e-01,  1.0499e-01, -1.8936e-01, -1.8449e-01,\n",
       "                       -1.7273e-01,  2.0052e-01, -4.3784e-02, -4.2747e-01,  9.6687e-02],\n",
       "                      [-1.4412e-01,  1.5435e-01,  8.7666e-02, -8.7351e-02, -1.1383e-01,\n",
       "                       -1.7911e-01, -1.7691e-01,  1.5535e-01,  1.8729e-01,  1.0104e-01,\n",
       "                        1.8229e-01, -2.2942e-03, -2.0348e-01,  1.1719e-01,  2.5614e-01,\n",
       "                        2.3979e-01, -1.5739e-01,  9.1571e-02, -7.8181e-02,  1.2008e-01,\n",
       "                        1.0561e-01, -1.5674e-01,  7.9113e-02, -9.5562e-02,  4.8744e-02,\n",
       "                        2.9410e-02, -3.2502e-01,  1.1360e-02,  6.6230e-03, -4.1901e-02,\n",
       "                        1.5902e-01, -1.5436e-01, -2.7756e-01, -7.4812e-02,  6.5144e-02,\n",
       "                       -1.6778e-01,  5.5468e-02,  1.1282e-01, -3.6925e-02, -1.5188e-01],\n",
       "                      [-1.6947e-01, -3.0388e-01,  1.4025e-02,  2.3217e-02,  1.7646e-02,\n",
       "                        1.9399e-01,  2.8692e-02, -1.2885e-02,  3.4242e-01, -6.9250e-01,\n",
       "                        3.0103e-02, -2.0202e-01, -2.6838e-02,  2.4803e-02,  6.0738e-02,\n",
       "                        4.1929e-03,  2.0170e-01,  4.1061e-02, -5.4970e-03,  1.1136e-01,\n",
       "                        9.8283e-02,  2.2743e-01,  1.3839e-01, -1.2535e-01,  9.5920e-02,\n",
       "                       -6.3057e-01,  1.7711e-01, -9.3267e-02, -8.6557e-02, -9.6643e-02,\n",
       "                       -7.8345e-02,  2.6133e-03, -2.3907e-02, -2.1089e-01,  1.2667e-01,\n",
       "                       -8.7669e-03,  1.5026e-01,  1.1228e-01, -2.4634e-01,  7.5728e-02],\n",
       "                      [ 1.2734e-02, -1.0168e-01,  1.3178e-01,  4.7322e-02, -1.3662e-01,\n",
       "                        3.8513e-01,  3.5106e-01, -7.3681e-02, -7.4446e-02,  7.6300e-02,\n",
       "                       -4.5798e-04, -1.2273e-01,  9.1421e-02, -1.2838e-01,  1.1112e-01,\n",
       "                       -4.9859e-01, -1.3040e-01,  4.6939e-03,  1.8350e-01, -1.2827e-01,\n",
       "                       -1.3560e-01, -1.6005e-01,  1.5576e-02, -1.2715e-01, -8.1335e-02,\n",
       "                        8.0768e-02, -7.9610e-02,  8.8145e-02, -1.1393e-02,  1.1334e-01,\n",
       "                       -4.7203e-01, -9.3547e-02, -9.5584e-02,  2.0267e-01,  1.7993e-01,\n",
       "                        1.3804e-01, -6.7159e-02,  2.4568e-01, -3.3782e-02,  2.0533e-02]])),\n",
       "             ('classifier.2.bias',\n",
       "              tensor([ 0.5175,  0.0145, -0.0213,  0.2814,  0.3952,  0.1656, -0.4543, -0.1784,\n",
       "                       0.1316, -0.2335,  0.4755, -0.3006,  0.0388, -0.1272, -0.1613,  0.2608,\n",
       "                       0.0271, -0.0517,  0.0742, -0.0005])),\n",
       "             ('classifier.3.weight',\n",
       "              tensor([[-4.7081e-01,  7.5830e-03, -2.7573e-01, -1.4219e-01, -2.6841e-01,\n",
       "                        2.4292e-02,  6.7988e-01,  1.2204e-01,  3.2551e-03,  1.8556e-01,\n",
       "                       -2.9881e-01, -6.4504e-02, -2.0698e-01,  1.8367e-01,  7.5338e-02,\n",
       "                       -2.9971e-01, -1.3611e-01,  5.1026e-03, -1.6992e-01,  1.8883e-01],\n",
       "                      [-2.0502e-01,  3.9391e-01, -2.6852e-02,  4.6519e-02, -8.9996e-02,\n",
       "                        2.4501e-02,  9.6111e-02, -1.7381e-02, -4.6123e-02,  3.1042e-01,\n",
       "                       -3.8206e-01,  9.7328e-02, -5.6264e-02,  8.0537e-02,  3.3521e-01,\n",
       "                       -8.4119e-02, -4.3989e-01,  8.0535e-02, -1.7345e-02,  8.1880e-03],\n",
       "                      [-1.7692e-01, -1.7603e-01,  6.4127e-02, -7.2822e-02, -2.2501e-01,\n",
       "                       -2.7343e-02, -6.2973e-02,  8.7949e-02, -2.1807e-02,  5.6029e-01,\n",
       "                       -1.0771e-01, -9.8164e-02,  9.1348e-02,  6.4134e-02, -9.6597e-02,\n",
       "                       -7.6401e-02,  2.2119e-01,  3.6510e-01,  9.4998e-02,  2.8808e-01],\n",
       "                      [-2.8343e-01, -1.1526e-01, -1.7698e-01, -3.4435e-01, -4.1720e-02,\n",
       "                       -1.1193e-01,  5.3930e-01, -7.2306e-02, -7.5204e-02, -2.1552e-01,\n",
       "                       -2.0369e-02,  2.2213e-01,  3.3935e-02,  2.0151e-02,  6.7688e-01,\n",
       "                       -3.7415e-01,  1.9172e-01,  1.1201e-01, -1.2794e-02,  2.5295e-01],\n",
       "                      [ 6.8559e-02,  1.2252e-01,  3.5580e-01, -2.9371e-02, -4.1039e-01,\n",
       "                        1.8675e-01, -4.5927e-02,  6.0262e-02,  7.4913e-02,  9.5341e-03,\n",
       "                       -2.6638e-01,  4.3078e-01, -2.0739e-01,  3.1544e-02,  2.0904e-01,\n",
       "                       -1.0035e-01,  2.0962e-01, -9.4126e-02, -4.2666e-02,  1.2539e-01],\n",
       "                      [ 1.5775e-01, -5.6583e-02, -3.7584e-02,  1.3560e-01,  1.3067e-01,\n",
       "                       -7.0705e-02, -1.8627e-01, -3.4924e-01, -3.6146e-01, -3.6642e-01,\n",
       "                       -2.1081e-01,  1.3633e-01,  3.4123e-01, -1.0524e-01, -1.3342e-01,\n",
       "                        2.4022e-02, -4.8089e-02, -4.7011e-02,  4.5730e-01, -4.9656e-02],\n",
       "                      [-3.5238e-02, -4.8573e-01,  1.1872e-01, -1.1536e-01,  1.1619e-02,\n",
       "                        2.7656e-01,  2.2043e-01, -3.7856e-01,  1.8529e-01,  1.1521e-02,\n",
       "                       -8.4700e-02, -1.7110e-01, -5.7230e-02,  1.7514e-01,  1.6300e-01,\n",
       "                        2.4467e-02,  5.4506e-03, -5.8937e-02,  3.5435e-01,  3.5801e-02],\n",
       "                      [-2.1751e-01, -1.2191e-01, -4.0109e-01,  2.7282e-02,  1.6194e-01,\n",
       "                        1.7947e-01,  6.2115e-03, -4.8241e-02, -4.1667e-02,  2.0068e-01,\n",
       "                       -1.5679e-01, -1.6083e-01, -2.2092e-01,  5.3442e-02, -7.8932e-02,\n",
       "                        2.6030e-01,  2.8627e-01,  2.0110e-01,  1.8919e-01,  5.9829e-02],\n",
       "                      [-1.9750e-01,  1.6248e-01,  4.0721e-01,  1.4925e-01, -9.2486e-02,\n",
       "                        1.5732e-01,  2.0523e-01, -7.6315e-02,  1.0468e-01,  9.9645e-02,\n",
       "                       -1.2056e-01, -2.3920e-01, -1.9162e-02, -2.6207e-01, -9.6266e-02,\n",
       "                       -1.1561e-01,  1.4777e-01,  2.3353e-01, -2.8175e-02,  1.1157e-01],\n",
       "                      [-5.3325e-01,  1.1241e-01, -1.6458e-01, -3.3437e-01, -5.5975e-02,\n",
       "                       -2.7016e-01,  4.5748e-01, -7.1567e-02, -9.8279e-02,  2.1002e-01,\n",
       "                       -5.8707e-01,  1.9112e-01, -4.1954e-02, -1.3836e-01,  3.7542e-01,\n",
       "                        1.5714e-01, -9.5831e-02,  1.9319e-01,  8.8216e-03, -4.7113e-02],\n",
       "                      [-9.3593e-02,  1.4521e-01,  3.8407e-04,  1.7025e-01,  1.2765e-01,\n",
       "                       -1.2687e-01,  4.0915e-01, -2.3756e-01, -4.2392e-02,  2.8009e-01,\n",
       "                       -1.8873e-02,  1.4269e-01, -1.0478e-02,  3.0318e-01, -1.0951e-01,\n",
       "                       -1.5090e-01, -5.4388e-01, -6.8261e-02,  1.4424e-01,  1.6751e-01],\n",
       "                      [-2.4305e-01,  2.3782e-01, -3.4681e-02,  8.4948e-02, -1.1434e-01,\n",
       "                       -8.5599e-02,  2.0540e-01, -5.3259e-02, -1.3625e-01, -2.4570e-01,\n",
       "                       -1.2994e-02,  3.3289e-01, -3.9668e-01,  3.2044e-01,  2.3273e-01,\n",
       "                        1.3361e-01, -2.9708e-01, -2.0645e-01,  2.9103e-01,  2.1869e-01],\n",
       "                      [-7.7939e-02, -2.2287e-01,  2.4992e-01, -2.7289e-01,  3.4805e-02,\n",
       "                       -3.7708e-01, -1.6316e-01, -1.4553e-01, -2.2320e-02,  6.2117e-02,\n",
       "                        1.1768e-02, -2.5443e-01,  2.5738e-01, -5.2772e-01,  3.5695e-01,\n",
       "                       -4.1878e-01,  3.7455e-01,  4.5774e-01,  5.5124e-02, -3.5076e-01],\n",
       "                      [-1.5027e-01, -3.2464e-02,  6.4860e-02,  1.8568e-01, -2.0916e-01,\n",
       "                       -2.8894e-02, -1.1722e-02,  2.1285e-01, -2.7057e-01, -1.8806e-01,\n",
       "                       -8.7356e-02,  1.1658e-01,  3.6870e-01, -3.0050e-01, -1.1333e-01,\n",
       "                       -3.0600e-02,  2.1540e-01, -2.2669e-01, -3.2191e-02, -4.1864e-01],\n",
       "                      [-8.2625e-01,  3.7868e-02,  4.3743e-01, -4.3418e-03, -6.7317e-01,\n",
       "                        1.0810e-01,  4.5492e-01, -5.3138e-01, -1.7844e-01,  1.9280e-01,\n",
       "                       -2.0848e-01, -1.1133e-01,  2.6756e-01,  1.2091e-01,  9.3796e-03,\n",
       "                        3.4112e-01,  9.2517e-02, -2.2411e-03,  2.9172e-01, -3.0588e-02],\n",
       "                      [ 1.4169e-02,  1.7455e-01, -1.4011e-01,  2.0849e-01, -2.7454e-01,\n",
       "                        9.2260e-02, -1.5738e-01, -1.7718e-01, -3.0855e-02,  1.3310e-01,\n",
       "                       -4.0180e-02,  1.6469e-01, -1.5311e-01,  1.6681e-02, -8.2211e-02,\n",
       "                       -1.4548e-01, -2.1773e-01, -7.6460e-02, -6.0878e-02,  3.5435e-01],\n",
       "                      [-6.9775e-02, -2.5508e-01,  1.0419e-01, -2.0314e-01, -1.7671e-01,\n",
       "                       -2.6404e-01,  5.4576e-02,  3.0160e-01, -6.8657e-01,  1.3668e-01,\n",
       "                       -2.6830e-02,  3.3919e-01, -1.3800e-01, -4.1372e-01, -4.5644e-02,\n",
       "                       -1.0935e-01, -1.2202e-01, -9.7875e-02,  5.0546e-01,  1.5133e-02],\n",
       "                      [-8.6678e-02, -1.3834e-01, -5.1079e-01, -1.6008e-02, -5.3906e-01,\n",
       "                        8.1346e-03, -1.8867e-02,  3.5418e-01,  1.1382e-01,  1.6102e-01,\n",
       "                       -2.3299e-01, -7.4822e-02,  5.7144e-02, -5.2727e-02, -1.8600e-02,\n",
       "                       -3.0203e-01, -4.8097e-01, -1.6077e-01, -1.6671e-01, -7.9478e-02],\n",
       "                      [ 1.0785e-01,  8.6686e-02,  5.0219e-02,  1.9394e-01, -3.2567e-01,\n",
       "                       -2.1183e-01, -2.0874e-01, -1.8320e-01, -2.8051e-02,  2.9566e-02,\n",
       "                        1.8858e-01, -9.8400e-02,  3.5758e-01, -1.2226e-01, -6.4475e-02,\n",
       "                        1.9114e-01, -1.4591e-01, -4.1147e-02,  1.5399e-01, -4.1086e-01],\n",
       "                      [-2.8401e-01, -1.8894e-02,  4.1344e-02,  2.0857e-01,  1.3365e-01,\n",
       "                       -3.4953e-01,  5.0134e-02, -1.7632e-01, -3.4985e-01, -1.4971e-01,\n",
       "                       -3.6479e-01, -1.6132e-02,  1.5183e-01,  1.1606e-01,  2.1842e-01,\n",
       "                        1.6437e-01, -5.8622e-01, -4.1321e-02,  1.6534e-01, -2.6855e-01],\n",
       "                      [-4.9153e-01, -1.4018e-01, -2.1828e-01, -3.9232e-01, -5.6381e-02,\n",
       "                        7.9665e-02,  3.8412e-01, -2.6508e-01,  5.3380e-01,  4.0500e-01,\n",
       "                       -2.0925e-01, -2.7104e-01, -5.2759e-02,  4.9293e-01, -1.9711e-02,\n",
       "                        3.3364e-01,  1.7905e-01,  1.7142e-01, -2.5444e-01, -7.8010e-02],\n",
       "                      [-4.8415e-01, -9.2529e-03, -1.8395e-01, -2.6279e-01, -2.5223e-01,\n",
       "                        1.5586e-01,  4.2352e-01, -1.1891e-01, -1.5356e-01,  1.2940e-01,\n",
       "                       -7.2824e-02, -9.1599e-03, -7.2109e-02,  9.3360e-02,  2.3452e-01,\n",
       "                       -2.9970e-01, -4.8559e-01,  2.5611e-01, -1.6203e-01, -5.1121e-04],\n",
       "                      [-4.2211e-02, -4.0217e-03,  1.7026e-01, -1.7845e-01, -1.6658e-01,\n",
       "                       -3.8485e-01,  1.4916e-01, -1.5159e-01,  2.6232e-01,  3.3538e-01,\n",
       "                       -1.2313e-01,  1.1210e-01,  1.4819e-01, -4.5410e-01,  1.1327e-01,\n",
       "                       -3.2379e-01,  1.8001e-01,  4.0061e-01,  1.6082e-01, -1.1341e-01],\n",
       "                      [-5.4126e-01,  1.2893e-01, -1.3361e-01, -5.2548e-01,  2.4283e-01,\n",
       "                       -2.0445e-01,  4.3483e-01, -4.4298e-02,  2.3698e-02, -1.5499e-01,\n",
       "                       -4.2200e-01,  2.8370e-01,  1.2796e-01,  1.1774e-02,  5.7364e-01,\n",
       "                       -1.6000e-01, -1.4022e-02,  2.0008e-01,  6.9051e-02, -3.0879e-01],\n",
       "                      [ 1.7933e-02, -1.4707e-01, -2.4180e-01, -1.0649e-01,  1.4571e-01,\n",
       "                        3.7035e-01, -3.9465e-02, -2.5364e-01, -1.6117e-01, -3.1154e-01,\n",
       "                       -3.0293e-02, -1.9261e-01, -2.5510e-01,  1.3055e-01,  3.3144e-01,\n",
       "                       -2.3888e-01, -2.0036e-01, -4.0360e-02,  3.4309e-01,  1.8419e-01],\n",
       "                      [-4.2833e-02,  1.7022e-01,  8.1221e-02, -2.1458e-01, -1.9818e-01,\n",
       "                       -3.2507e-01,  3.8821e-02, -1.4006e-01,  6.6615e-03, -3.6256e-02,\n",
       "                       -4.8885e-01,  1.4548e-01,  3.5072e-01,  4.4771e-02,  1.8089e-02,\n",
       "                       -1.5365e-01, -1.1827e-01, -7.2435e-02,  3.5508e-01, -2.1267e-01],\n",
       "                      [-1.7076e-01,  1.3850e-01,  2.1522e-01, -2.4383e-03, -4.4982e-01,\n",
       "                        1.5801e-02, -7.2084e-02, -3.1959e-01, -2.6618e-01,  2.2899e-01,\n",
       "                       -4.4714e-01,  1.9662e-01,  8.4591e-02,  1.8069e-02,  8.8178e-02,\n",
       "                       -2.6005e-01, -1.9958e-02, -1.2318e-01,  8.6308e-03,  1.1430e-02],\n",
       "                      [-1.1777e-01,  3.7191e-02,  3.9757e-01,  1.1393e-01, -3.9533e-01,\n",
       "                       -1.0073e-03,  6.2915e-01,  1.6860e-01,  1.8761e-01, -9.5470e-03,\n",
       "                       -1.1613e-01,  4.3277e-01,  1.8044e-01,  3.7125e-01, -1.2821e-01,\n",
       "                       -7.3873e-01, -1.4893e-01,  1.7248e-01, -3.9744e-01,  5.9486e-02],\n",
       "                      [-2.4393e-01, -9.7006e-02,  9.9159e-03, -3.1534e-01, -9.7468e-02,\n",
       "                        1.5817e-01,  3.9103e-01, -5.0243e-01,  1.2557e-01, -3.6246e-01,\n",
       "                        6.3308e-03, -3.2162e-01,  1.1074e-01, -1.5772e-01,  5.6139e-01,\n",
       "                        2.3124e-01,  1.6198e-01, -6.6621e-02,  3.4735e-01, -9.5799e-02],\n",
       "                      [ 6.9524e-02,  9.1989e-02,  2.0565e-01,  1.9699e-02, -2.4365e-01,\n",
       "                       -5.4948e-02, -3.0680e-01, -2.0748e-01, -1.1240e-01, -3.3853e-01,\n",
       "                       -1.0283e-01, -1.1846e-01, -4.1536e-01, -2.1222e-01, -7.7847e-02,\n",
       "                        2.2161e-01,  1.3593e-01, -3.2370e-01, -1.7341e-02,  4.1597e-01],\n",
       "                      [-6.9087e-01, -8.6538e-02,  4.9489e-02, -7.7483e-02, -4.7540e-01,\n",
       "                       -4.1396e-01,  5.4768e-01,  7.5516e-02, -1.5227e-01,  2.0890e-01,\n",
       "                       -1.9688e-01,  4.1975e-01,  5.6254e-02, -1.2883e-01,  1.6287e-01,\n",
       "                        7.1229e-02, -3.2106e-01,  7.8420e-02, -1.1710e-01,  2.2073e-02],\n",
       "                      [-5.8089e-02,  9.7259e-02, -8.1685e-02,  9.5239e-02, -7.3179e-01,\n",
       "                       -4.1634e-01, -1.6007e-01,  1.6080e-01, -2.3681e-01,  4.1607e-01,\n",
       "                       -3.8577e-01,  2.4943e-01, -2.1237e-01, -2.0670e-03, -6.6081e-02,\n",
       "                       -2.9848e-01, -3.9535e-01,  8.2435e-02, -1.8563e-01,  1.0355e-01],\n",
       "                      [-3.9200e-01,  5.4852e-02, -1.4966e-02,  5.1555e-02, -1.5421e-01,\n",
       "                       -6.7262e-02,  2.8602e-01, -2.4468e-01, -1.6700e-02,  3.4821e-01,\n",
       "                       -1.2924e-01, -2.6663e-01, -5.0227e-02,  1.6523e-01, -4.4445e-02,\n",
       "                        2.8501e-01, -1.1338e-02,  9.7922e-02, -3.1837e-01,  6.3194e-02],\n",
       "                      [-3.3373e-01, -4.6503e-02, -2.6125e-01,  6.5443e-02, -6.4629e-02,\n",
       "                       -2.6218e-01, -1.8742e-02,  5.4639e-02, -2.9367e-01,  2.2575e-01,\n",
       "                       -1.9505e-01,  1.2917e-01,  4.7128e-02,  1.4340e-01, -1.5853e-01,\n",
       "                       -4.2269e-03, -4.7362e-01, -8.5296e-02, -9.2657e-02, -3.5232e-02],\n",
       "                      [-2.7434e-01,  2.2778e-01,  1.8954e-01, -7.0007e-02, -7.9098e-01,\n",
       "                       -1.2563e-01,  1.0656e-01,  1.6878e-02,  1.1112e-02,  2.4599e-01,\n",
       "                       -6.1621e-01,  2.5527e-01, -1.3883e-01, -1.4767e-01,  2.2084e-01,\n",
       "                       -6.4827e-02,  1.9436e-02, -6.3162e-02,  2.6335e-02,  1.5002e-01],\n",
       "                      [-2.4109e-01,  2.2506e-01,  8.7205e-02, -3.2566e-01, -1.1778e-02,\n",
       "                       -7.6375e-02,  3.5303e-01, -2.2123e-01, -7.7522e-02,  1.3001e-01,\n",
       "                       -4.4182e-01, -2.2364e-01,  2.3511e-01, -4.9446e-02,  3.4275e-01,\n",
       "                        1.5440e-01, -6.4684e-02,  1.8347e-01, -3.2146e-01, -4.1768e-02],\n",
       "                      [-3.1902e-01, -1.4115e-01, -1.5730e-02, -5.5907e-01, -1.0515e-01,\n",
       "                       -2.2030e-01,  5.3584e-01,  1.0365e-02, -1.0016e-01,  4.2646e-02,\n",
       "                       -9.9673e-02,  2.3110e-02,  2.0711e-01,  5.1121e-02,  6.9894e-01,\n",
       "                       -6.8458e-04, -3.2936e-02,  2.5499e-01, -2.3931e-01,  9.3782e-02],\n",
       "                      [-7.9300e-02, -2.1036e-01, -3.2196e-02,  1.6305e-01, -3.1278e-02,\n",
       "                        8.9922e-02,  1.0280e-01,  6.3322e-02,  1.4184e-01,  3.6080e-01,\n",
       "                        1.9893e-01, -7.4856e-02, -1.2678e-01,  1.7667e-02, -2.1851e-01,\n",
       "                       -6.6426e-02,  1.2180e-01,  2.5452e-01, -1.5751e-01,  5.3997e-02],\n",
       "                      [-8.9587e-02, -2.1542e-01,  2.0460e-01,  4.0936e-02,  1.2114e-01,\n",
       "                        1.1269e-01,  1.6535e-01,  1.4271e-01, -4.5679e-02, -2.0027e-01,\n",
       "                        2.5066e-02,  3.2005e-01,  2.5673e-01,  3.7840e-01,  1.1883e-01,\n",
       "                       -4.2929e-01, -2.0695e-01,  1.4763e-01, -2.2183e-01, -1.0586e-02],\n",
       "                      [-6.8351e-02,  1.0590e-01, -2.0421e-01, -8.6555e-02, -3.8170e-01,\n",
       "                       -9.3201e-02, -1.3780e-01,  2.9714e-01, -5.1624e-03,  1.2116e-01,\n",
       "                       -4.2040e-01,  2.3743e-01,  2.1695e-01,  1.0730e-01, -1.9303e-01,\n",
       "                       -2.9324e-01, -1.0679e-01, -1.2230e-01, -8.3948e-02, -3.3492e-02]])),\n",
       "             ('classifier.3.bias',\n",
       "              tensor([-0.2474,  0.0962, -0.3867, -0.4989, -0.2303,  0.0653, -0.1881, -0.0136,\n",
       "                      -0.1266, -0.7557,  0.2064, -0.4886,  0.1156, -0.3104, -0.3742, -0.0910,\n",
       "                      -0.7898, -0.1474,  0.2054, -0.3566, -0.0297, -0.2336, -0.3193, -0.4668,\n",
       "                       0.3053, -0.6628, -0.2400, -0.6250,  0.1799, -0.0923, -0.5215, -0.4055,\n",
       "                      -0.1031, -0.4336, -0.2750, -0.0564, -0.6541,  0.1964, -0.5450, -0.3999])),\n",
       "             ('classifier.5.weight',\n",
       "              tensor([[ 1.3306e-01,  1.8482e-01,  1.0194e-01,  ..., -1.2502e+00,\n",
       "                       -4.9227e-03, -1.7414e-02],\n",
       "                      [-3.1852e-01,  2.5387e-01, -3.6251e-02,  ..., -6.9061e-02,\n",
       "                        1.4925e-01, -7.5668e-02],\n",
       "                      [ 7.5630e-02,  2.5132e-01, -3.1225e-02,  ...,  9.0363e-02,\n",
       "                       -2.3753e-01,  5.8434e-01],\n",
       "                      ...,\n",
       "                      [ 2.3836e-01, -1.7217e-01,  1.7311e-01,  ...,  5.1755e-01,\n",
       "                        1.1451e-01,  5.5411e-01],\n",
       "                      [ 6.1262e-02, -3.3638e-02,  5.3863e-04,  ..., -1.5519e-01,\n",
       "                       -6.3843e-02, -1.0811e-01],\n",
       "                      [-6.8099e-02, -9.2728e-02,  3.3877e-01,  ..., -1.1976e-01,\n",
       "                        2.8249e-01,  1.4822e-01]])),\n",
       "             ('classifier.5.bias',\n",
       "              tensor([-0.1308,  0.1030,  0.1267, -0.0666, -0.0613,  0.4103,  0.0479,  0.0998,\n",
       "                      -0.1504,  0.0691,  0.1012, -0.1428,  0.0597,  0.1899,  0.3041, -0.0564,\n",
       "                       0.5632,  0.1733,  0.1954, -0.1826, -0.0478,  0.0654,  0.1379,  0.1210,\n",
       "                       0.1259, -0.0603, -0.0402, -0.0956,  0.1471,  0.0671,  0.1954, -0.0753,\n",
       "                      -0.0775,  0.4593,  0.1338, -0.0759, -0.0193,  0.1067, -0.1851, -0.0682])),\n",
       "             ('output.weight',\n",
       "              tensor([[-0.0262,  0.0865, -1.8039,  0.0301,  0.0514, -0.8965,  0.0246,  0.1147,\n",
       "                        0.0086, -0.1052, -0.1428, -0.0409,  0.0292, -0.3032, -1.3187,  0.1442,\n",
       "                       -1.0137, -1.1594, -1.7114,  0.0856, -0.1952, -0.0184, -0.2582, -0.1644,\n",
       "                        0.1112,  0.0126, -0.2563,  0.0422,  0.1493, -0.1287,  0.0607,  0.1801,\n",
       "                       -0.1948, -0.9137,  0.1132,  0.1622, -0.1229, -2.1485, -0.0545,  0.0386],\n",
       "                      [-0.1947,  0.0651,  0.0423, -0.1845, -0.1900,  0.1111, -0.1264,  0.1236,\n",
       "                        0.0064, -0.1247,  0.1122, -0.0478,  0.0266,  0.0879,  0.1201, -0.1136,\n",
       "                       -0.0439,  0.0650,  0.1954, -0.0810, -0.1865, -0.0361,  0.1091, -0.0765,\n",
       "                        0.1065, -0.2159,  0.1534, -0.1994,  0.1131, -0.0384,  0.0438, -0.0103,\n",
       "                       -0.1673,  0.1535,  0.1001, -0.0535,  0.0366,  0.0394, -0.1038, -0.1685],\n",
       "                      [-0.1898, -0.2121,  0.1602,  0.0234,  0.0502,  0.0968, -0.1677, -0.1416,\n",
       "                        0.0380,  0.0650, -0.1265,  0.0473, -0.2996, -0.0904,  0.1072,  0.1383,\n",
       "                       -0.0398,  0.2001,  0.0646, -0.0855,  0.0305, -0.2599, -0.2001,  0.1095,\n",
       "                       -0.1752, -0.0176, -0.1028,  0.0166, -0.0825,  0.1193, -0.1915,  0.1822,\n",
       "                        0.0942,  0.1704, -0.1392,  0.1223,  0.0286,  0.0680, -0.0816,  0.0403]])),\n",
       "             ('output.bias', tensor([-1.2432, -0.0050,  0.0236]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파라미터 확인\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c4a5f4",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f39240",
   "metadata": {},
   "source": [
    "## Sample Data\n",
    "- Inference를 위해 Validation set에서 각 label에 해당하는 데이터를 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "127649e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1       98\n",
       "x2      107\n",
       "x3      121\n",
       "x4      143\n",
       "x5      166\n",
       "       ... \n",
       "x174     95\n",
       "x175    107\n",
       "x176    111\n",
       "x177    110\n",
       "x178    119\n",
       "Name: 11487, Length: 178, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label = 0인 Validation set의 sample\n",
    "test_x.iloc[0] # 원본 데이터에서의 index : 9003\n",
    "test_x.iloc[495] # 원본 데이터에서의 index : 11487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea806f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1     -18\n",
       "x2     -12\n",
       "x3      -5\n",
       "x4      -4\n",
       "x5      -3\n",
       "        ..\n",
       "x174   -41\n",
       "x175   -30\n",
       "x176   -26\n",
       "x177   -17\n",
       "x178   -17\n",
       "Name: 11484, Length: 178, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label = 1인 Validation set의 sample\n",
    "test_x.iloc[504] # 원본 데이터에서의 index : 8872\n",
    "test_x.iloc[996] # 원본 데이터에서의 index : 11484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "465c8590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1     -39\n",
       "x2     -16\n",
       "x3     -13\n",
       "x4     -14\n",
       "x5     -68\n",
       "        ..\n",
       "x174   -66\n",
       "x175   -49\n",
       "x176   -34\n",
       "x177   -31\n",
       "x178   -52\n",
       "Name: 11494, Length: 178, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label = 2인 Validation set의 sample\n",
    "test_x.iloc[1003] # 원본 데이터에서의 index : 9055\n",
    "test_x.iloc[2496] # 원본 데이터에서의 index : 11494"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92841cba",
   "metadata": {},
   "source": [
    "## Inference 진행\n",
    "- 위에서 언급한 각각의 sample에 대해 inference 진행\n",
    "- 원본 데이터 d를 전처리하고 정규화한 validation set이므로 원본 데이터의 인덱스가 아닌 validation set의 인덱스를 넣어줘야 함\n",
    "- label 0 : 0, 495\n",
    "- label 1 : 504, 996\n",
    "- label 2 : 1003, 2496\n",
    "- 랜덤한 input을 위해 randint 함수로 랜덤한 정수를 만들고, 120의 길이만큼 데이터를 가져옴\n",
    "- 랜덤한 범위에 대해 feature를 잘라 가져오기 때문에 첫 시행에서 잘못 예측하더라도 다음 예측에서는 대부분 옳은 예측을 하는 경우가 많았음\n",
    "- 파라미터를 업로드하고, 가져온 sample data를 myRNN의 input 형태에 맞게 view함수를 통해 shape 조절\n",
    "- .eval() 함수를 호출하여 평가단계에서 진행\n",
    "- softmax 함수와 argmax 함수를 통해 가장 큰 값을 가지는 인덱스를 구해서 result를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bb59c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(test_x_st[1003])\n",
    "r2 = random.randint(0,40)\n",
    "a = a[r2:r2+120]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "net = net.to(device)\n",
    "\n",
    "model_state_dict = torch.load(PATH_param, map_location=device)\n",
    "net.load_state_dict(model_state_dict)\n",
    "\n",
    "net.eval()\n",
    "X = a.view(1,8,15).to(torch.float32)\n",
    "with torch.no_grad():\n",
    "    y_vd_pred = net(X.to(device))\n",
    "y_vd_pred = y_vd_pred[:,-1,:]            \n",
    "result = torch.argmax(y_vd_pred.cpu().softmax(1),dim=1) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411fafc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc78f6c",
   "metadata": {},
   "source": [
    "# 분석 결과\n",
    "- 1. EEG 신호가 sequential data이기 때문에, 전반적으로 높은 예측을 보여줄 것이라 생각한 RNN모델을 사용하였다. 수업시간에 다룬 3가지 방법(vanila RNN, GRU, LSTM) 중에서 LSTM 이 가장 좋은 퍼포먼스를 보여주었기 때문에 LSTM을 선택했다.\n",
    "- 2. 만들고자 하는 모델은 사용자의 EEG sequence를 넣었을때 그 사람이 어떤 상태(간질발작, 종양, 건강)에 놓여있는지를 파악하는 모델이다. 측정을 위한 전극의 위치나 개수에 따라 그 신호의 개수가 달라질 수 있을 것이라 생각하였기 때문에, 임의의 랜덤한 부분에서 120개의 신호를 가져올 수 있도록 data_iter와 모델을 설계하였다. 이는 inference부분에도 동일하게 구현해두었다.\n",
    "- 3. 학습결과 전반적으로 높은 accuracy를 보여주었기에 vallidation data를 input으로 입력했을 때 결과 역시 대부분의 경우에 제대로 예측했다. 그래도 제대로 파악하지 못하는 몇가지 경우(test_x_st[1003], label = 2)를 분석하기 위해 BMEAI_Project_1_train.ipynb 파일에서 신호의 파형을 출력해 보았다. test_x_st[1003]의 경우에는 원래 label이 2지만, 실제 inference를 돌려보면 1로 예측하는 경우가 존재했다. 이는 아래의 그림에서 보듯이 label이 1인 [996]과 비슷한 패턴이 [1003]의 파형에 존재하기 때문으로 사료된다. 랜덤한 범위에서 L개의 데이터만을 추출하도록 설계해 두었기 때문에, 그 유사한 부분을 함께 가져오면서 잘못된 예측을 할 가능성이 생긴 것 같다. 어쩌면 label 2를 결정하는 부분이 파형에 존재하는 잘은 변화들 때문인 듯 한데, [1003]의 파형은 [2496]과는 다르게 그 자잘함이 눈에 띄지는 않는다. 하지만, inference를 다시 진행하여 새로운 L의 범위를 랜덤하게 받아오면 제대로 예측하는 것을 확인할 수 있었다. \n",
    "<p align=\"center\"><img src=\"https://user-images.githubusercontent.com/65170165/173314960-42de1884-67fd-42c2-bbe1-58e913b7418f.png\" width=\"900\" /></p>\n",
    "- 4. 3에서의 예 뿐만 아니라 서로 다른 label을 가지고 있으나 유사한 부분이 신호에 존재하는 경우에는 예측이 틀리는 경우가 존재하였다. 이는 아무래도 랜덤하게 추출하는 과정에서 신호의 이어짐이 끊긴 이유도 있을 테지만, 기장 큰 이유는 사람이 신호의 파형만을 보고 EEG 신호의 노이즈를 판별하여 분석해내기에는 어려움이 따르기 때문이라고 생각한다. 반면 같은 이유로 inference를 할때 랜덤한 구간 L을 설정해주기 때문에 잘못 예측한 경우 역시 inference를 다시 진행해보면 대다수가 원래의 label과 일치하는 것을 확인할 수 있었다.\n",
    "- 5. 무의식적인 뒤척거림이나 눈 움직임에 의해 신호에 큰 변화가 일어나는 EEG 신호를 사용했기 때문에 이를 어느정도 보정해주기 위한 적절한 표준화 방법이 필요했다. 따라서 신호의 noise를 제거해주기 위해 moving average와 MinMaxScaler, StandardScaler를 각각 적용해보았는데 StandardScaler의 경우에 가장 좋은 결과를 나타냈기 때문에 이 method를 선택해서 학습을 진행했다. \n",
    "- 6. 모델의 일반성을 확인해보기 위해서 다른 EEG data(945 rows, 1149 columns)를 적용해서 classification을 진행하였으나, 이 데이터에 대해서는 좋은 결과를 얻지 못했다. 우선적으로 데이터의 7개의 label들에 대한 분포가 고르지 않았다. 또한 본 프로젝트에 사용한 데이터(11500 rows, 179 columns)에 비해 column의 수는 많지만, 그 수많은 EEG 신호에 대한 노이즈를 잡아 결과를 얻기에는 object의 수가 너무 적었기 때문이라고 생각한다.\n",
    "- 7. 결론적으로 EEG 신호처럼 노이즈가 많은 데이터를 분석하기 위해서는 이를 잘 설명해줄 수 있을 만한 충분한 수의 데이터와 적절한 scaler 방법이 필요하다고 생각한다. 또한 앞서 말했듯이 사람이 이러한 노이즈를 잡아내고 패턴을 분석해서 그에 해당하는 인사이트를 도출하기는 너무 어렵기 때문에 EEG 신호와 같은 의학적 분야에 인공지능이 꼭 필요할 것이라고 결론을 내릴 수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0269ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9581cd16",
   "metadata": {},
   "source": [
    "# 배운 점\n",
    "- 데이터를 선정하고, 전처리하기까지의 어려움은 크게 없었던 것 같다. 하지만 이 데이터를 우리가 원하는 형태로 바꿔주고, 특히 모델과의 shape를 맞추는 데 시간이 굉장히 많이 걸렸던 것 같다. 이렇게 모델의 shape를 맞춰서 학습을 시작하는 것까지는 성공을 했지만, 그 뒤에 이어진 학습 단계에서 accuracy가 local optimum 에 빠지는 상황이 계속 발생해서 바꿀 수 있는 건 모두 바꿔봤던 것 같다. learning rate, epoch, optimization, loss function 그리고 각종 사이즈까지 모두 바꿔봤지만 도저히 상황이 나아지지 않았고, 밑져야 본전이라는 마음가짐으로 그냥 LSTM 함수의 num_layer를 바꾸었더니 이렇게 좋은 결과를 만들 수 있었다. 인터넷을 찾아보며 사서 고생을 정말 많이 한 것 같은데, 오히려 간단한 매개변수를 하나 바꿔줌으로써 완전히 상반된 결과를 만들 수 있다는  것이 신기한 한편 허무하기도 했다. 하지만 이런 과정을 통해 수업시간에 배운 optimize algorithm 외에도 수많은 종류가 있다는 것도 알 수 있었고, 그 중에 하나인 Adam을 선택해서 더 나은 accuracy를 얻을 수 있었다. 또한 수업시간에 수업을 들으면서도 이렇게 학습한 모델을 실제로 어떻게 사용하는지는 항상 궁금했는데, Inference 과정을 구현해보면서 그 방법을 배운 것 같아 재밌었다. 수업시간에 배우는 이론도, 그리고 실습코드를 사용해서 과제를 하는 것 역시 중요하지만 그래도 제일 기억에 남는 것은 역시 직접 시간을 들여서 찾아보고, 결론을 도출하기까지의 과정인 것 같다. 결과적으로 우리는 바이오메디컬인공지능 프로젝트를 통해 직접 데이터를 불러오고 모델에 적용하면서 그 shape 와 각종 하이퍼파라미터들을 맞추는 인공지능의 핵심을 배웠고, 그보다 중요한 하나의 인공지능을 구현해보았다는 경험을 얻을 수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2902252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c63cd4f",
   "metadata": {},
   "source": [
    "# 질문에 대한 답변\n",
    " - Q. class간 비율이 1:1:3으로 normal이 상대적으로 많은데 이로인한 문제가 없을까요?\n",
    " - Q. class별로 accuracy를 각각 분석하여 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799951fa",
   "metadata": {},
   "source": [
    " - 위 질문들에 대한 답을 위해 classification report와 confusion matrix를 출력했다. 그 결과는 아래와 같았다. \n",
    "<p align=\"center\"><img src=\"https://user-images.githubusercontent.com/65170165/174334834-cf138f57-f5af-4dd1-a266-74724441eae2.png\" width=\"900\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716f61bd",
   "metadata": {},
   "source": [
    "## Q. class간 비율이 1:1:3으로 normal이 상대적으로 많은데 이로 인한 문제가 없을까요?\n",
    " - 사실 첫번째 질문과 두번째 질문에 대한 답을 이 두개의 결과로부터 모두 알아볼 수 있을 것 같다. 에포크를 많이 돌려서 실험한 결과 accuracy는 계속 꾸준히, 그리고 굉장히 높은 수치까지 성장한 것을 확인했지만, 아래의 report에서 볼 수 있듯이 전체적인 accuracy는 생각보다 낮게 측정되었다. normal이 상대적으로 많이 데이터였기 때문에 데이터가 어느 정도 불균형하다는 것을 염두에 두고, accuracy보다는 f1-score에 좀 더 비중을 두고 분석하는 것이 좋을 수 있다고 생각하였다. 우리가 우선적으로 찾아내고 싶었던 target인 Epileptic_Seizures (label=0)에 대해서는 그 score가 0.97로 굉장히 높은 것을 확인할 수 있었고, 이에 대해서는 좋은 성능을 보이는 모델이라 할 수 있을 듯 하다. 또한 confusion matrix 에도 나타나 있듯이, 총 500개의 label 0 에 대해서 483개의 좋은 예측을 한 모델을 만들 수 있었다. 하지만 상대적으로 Tumor에 대한 f1-score 는 상당히 낮은 것을 확인할 수 있었다. 이는 아무래도 전체적인 신호의 파형이 tumor와 normal의 경우가 비슷한 부분들이 존재하기 때문에 tumor를 정확히 파악하기에는 tumor label에 대한 비율이 살짝 부족하지 않았을까 싶다. 결론적으로 상대적인 비율이 우리가 주 목적으로 한 Epileptic_Seizures를 알아내는 데에는 지장이 없었지만, 다른 label, 특히 Tumor를 파악하는 데에는 영향을 미쳤다고 생각한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79485e58",
   "metadata": {},
   "source": [
    " ## Q. class별로 accuracy를 각각 분석하여 주세요.\n",
    " \n",
    " class | accuracy\n",
    "--- | ---\n",
    "Epileptic_Seizures (0) | 0.966\n",
    "Tumor (1) | 0.652\n",
    "Normal (2) | 0.871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e2cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722234a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
